{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "import  gc\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    home_directory = os.path.expanduser('~/kaggle_HomeCredit/parquet_files/')\n",
    "    train_data_path = os.path.join(home_directory, 'train/')\n",
    "    test_data_path = os.path.join(home_directory, 'test/')\n",
    "    \n",
    "    train_applprev_path = 'train_applprev_*.parquet'\n",
    "    train_base_path =  'train_base_*.parquet'\n",
    "    train_credit_path = 'train_credit_bureau_*.parquet'\n",
    "    train_debitcard_path = 'train_debitcard_1.parquet'\n",
    "    train_deposit_path = 'train_deposit_1.parquet'\n",
    "    train_other_path = 'train_other_1.parquet'\n",
    "    train_person_path = 'train_person_*.parquet'\n",
    "    train_static_path = 'train_static_*.parquet'\n",
    "    train_tax__path = 'train_tax_registry_*.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def reduce_mem_usage(df, int_cast=True, obj_to_category=False, subset=None):\n",
    "    \"\"\"\n",
    "    データフレームの初期メモリ使用量を計算します。\n",
    "    全ての列をイテレートし、データ型を確認します。\n",
    "    数値型の列については、その範囲に基づいて、可能な限り小さい整数型または浮動小数点型に変換します。\n",
    "    オブジェクト型の列（文字列など）は、必要に応じてカテゴリ型に変換されます。これにより、特にカテゴリの数が少ない場合にメモリ使用量が削減されます。\n",
    "    変換後のデータフレームのメモリ使用量を再計算し、削減された割合を表示します。\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    gc.collect()\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "#     cols_none = subset if subset is  None else df.columns.tolist()\n",
    "#     for col_non in tqdm(cols_none):\n",
    "#         df[col_non] = df[col_non].fillna(-888)\n",
    "    \n",
    "    cols = subset if subset is not None else df.columns.tolist()\n",
    "\n",
    "    for col in tqdm(cols):\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "#             df[col] = df[col].fillna(-888)\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "#             # test if column can be converted to an integer\n",
    "#             treat_as_int = str(col_type)[:3] == 'int'\n",
    "#             if int_cast and not treat_as_int:\n",
    "#                 treat_as_int = check_if_integer(df[col])\n",
    "                \n",
    "            treat_as_int = True\n",
    "            if treat_as_int:\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "                    df[col] = df[col].astype(np.uint8, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "                    df[col] = df[col].astype(np.uint16, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "                    df[col] = df[col].astype(np.uint32, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "                    df[col] = df[col].astype(np.uint64, errors='ignore')\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16, errors='ignore')\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32, errors='ignore')\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64, errors='ignore')\n",
    "        elif 'datetime' not in col_type.name and obj_to_category:\n",
    "            df[col] = df[col].fillna('Mis')\n",
    "            df[col] = df[col].astype('category')\n",
    "    gc.collect()\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "def date_column_depth_0(df):\n",
    "    \"\"\"\n",
    "    特定の命名規則に基づいて日付列を特定し、それらを日付型に変換します。\n",
    "    'date_decision'列と他の日付列との差分（日数）を計算し、新しい列としてデータフレームに追加します。\n",
    "    \"\"\"\n",
    "    date_columns = ['date_decision'] + [x for x in df.columns if x[-1] == 'D'] \n",
    "    df[date_columns] = df[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "    df_diff = df[date_columns].apply(lambda col: (df['date_decision'] - col).dt.days)\n",
    "    df_diff.columns = [f'Diff_{col}' for col in df_diff.columns]\n",
    "    df = pd.concat([df, df_diff], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def union_parquest(list_parq):\n",
    "    \"\"\"\n",
    "    指定されたParquetファイルのリストからデータフレームを読み込みます。\n",
    "    各データフレームにreduce_mem_usage関数を適用し、メモリ使用量を削減します。\n",
    "    これらのデータフレームを結合し、再度メモリ使用量の削減を試みます。\n",
    "    \"\"\"\n",
    "    df_list = [reduce_mem_usage(pd.read_parquet(i)) for i in list_parq]\n",
    "    union_df = pd.concat(df_list)\n",
    "    union_df = reduce_mem_usage(union_df)\n",
    "    return union_df   \n",
    "\n",
    "def gini(x):\n",
    "    \"\"\"\n",
    "    配列内の各値に対して、他の全ての値との差の絶対値を計算し、これらの差の総和を求めます。\n",
    "    この総和を配列の長さの2乗と配列の平均値の積で正規化し、Gini係数を計算します。\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        total += np.sum(np.abs(xi - x[i:]))\n",
    "    return total / (len(x)**2 * np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge(base_data,train_vs_test,data_type):\n",
    "    if train_vs_test ==  'train':\n",
    "        file_path = CFG.train_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    elif train_vs_test ==  'test':\n",
    "        file_path = CFG.test_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    df_i_merged = pd.DataFrame()\n",
    "    \n",
    "    for i in list_parq:\n",
    "        print(i)\n",
    "        df_i = pd.read_parquet(i)\n",
    "        df_i = reduce_mem_usage(df_i)\n",
    "        if 'num_group1' in df_i.columns: \n",
    "            df_i = df_i[df_i['num_group1'] == 0 ]\n",
    "            df_i = df_i.drop(columns = 'num_group1')\n",
    "    #         df_i_merged = df_i_merged.merge(df_i,how = 'left',on = 'case_id')\n",
    "        df_i_merged = pd.concat([df_i_merged,df_i])\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    return df_i_merged        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge_v2(base_data,train_vs_test,data_type):\n",
    "    if train_vs_test ==  'train':\n",
    "        file_path = CFG.train_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    elif train_vs_test ==  'test':\n",
    "        file_path = CFG.test_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    df_i_merged = pd.DataFrame()\n",
    "    \n",
    "    for i in list_parq:\n",
    "        print(i)\n",
    "        df_i = pd.read_parquet(i)\n",
    "        df_i = reduce_mem_usage(df_i)\n",
    "        if 'num_group1' in df_i.columns: \n",
    "#             df_i = df_i[df_i['num_group1'] == 0 ]\n",
    "            df_i = df_i.drop(columns = 'num_group1')\n",
    "    #         df_i_merged = df_i_merged.merge(df_i,how = 'left',on = 'case_id')\n",
    "        df_i_merged = pd.concat([df_i_merged,df_i])\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    return df_i_merged        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge_depth_2(base_data,train_vs_test,data_type):\n",
    "    if train_vs_test ==  'train':\n",
    "        file_path = CFG.train_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    elif train_vs_test ==  'test':\n",
    "        file_path = CFG.test_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    df_i_merged = pd.DataFrame()\n",
    "    \n",
    "    for i in list_parq:\n",
    "        print(i)\n",
    "        df_i = pd.read_parquet(i)\n",
    "        df_i = reduce_mem_usage(df_i)\n",
    "        if 'num_group1' in df_i.columns: \n",
    "            df_i = df_i[df_i['num_group1'] == 0 ]\n",
    "            df_i = df_i.select_dtypes(exclude=['object'])\n",
    "            df_i = pd.pivot_table(df_i,index = 'case_id', aggfunc= {'max','min'})\n",
    "            df_i.columns = [f'{j}_{i}' if j != '' else f'{i}' for i,j in df_i.columns]\n",
    "            df_i = df_i.drop(columns = [ i for i in df_i.columns if 'num_group' in i])\n",
    "        df_i_merged = pd.concat([df_i_merged,df_i])\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    return df_i_merged        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 58.24 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 298.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 26.207 MB\n",
      "Decreased by 55.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train_base_df = pd.read_parquet(CFG.train_data_path + 'train_base.parquet')\n",
    "train_base_df = reduce_mem_usage(train_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_static_0_0.parquet\n",
      "Memory usage of dataframe is 1279.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [00:00<00:00, 183.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1045.325 MB\n",
      "Decreased by 18.3%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_static_0_1.parquet\n",
      "Memory usage of dataframe is 666.73 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [00:00<00:00, 392.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 547.050 MB\n",
      "Decreased by 18.0%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_static_cb_0.parquet\n",
      "Memory usage of dataframe is 606.73 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 182.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 601.006 MB\n",
      "Decreased by 0.9%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_applprev_1_0.parquet\n",
      "Memory usage of dataframe is 1216.09 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 61.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1175.304 MB\n",
      "Decreased by 3.4%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_applprev_1_1.parquet\n",
      "Memory usage of dataframe is 825.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 108.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 797.596 MB\n",
      "Decreased by 3.4%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_0.parquet\n",
      "Memory usage of dataframe is 2476.11 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 44.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2436.932 MB\n",
      "Decreased by 1.6%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_1.parquet\n",
      "Memory usage of dataframe is 3621.87 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 26.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3564.565 MB\n",
      "Decreased by 1.6%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_3.parquet\n",
      "Memory usage of dataframe is 1253.25 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 73.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1233.424 MB\n",
      "Decreased by 1.6%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_2.parquet\n",
      "Memory usage of dataframe is 2256.48 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2220.774 MB\n",
      "Decreased by 1.6%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_b_1.parquet\n",
      "Memory usage of dataframe is 29.45 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 1865.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 28.554 MB\n",
      "Decreased by 3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_debitcard_1.parquet\n",
      "Memory usage of dataframe is 7.20 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 796.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 5.551 MB\n",
      "Decreased by 22.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_deposit_1.parquet\n",
      "Memory usage of dataframe is 5.53 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1589.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3.459 MB\n",
      "Decreased by 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_person_1.parquet\n",
      "Memory usage of dataframe is 839.52 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 290.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 808.322 MB\n",
      "Decreased by 3.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_tax_registry_a_1.parquet\n",
      "Memory usage of dataframe is 124.96 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 246.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 78.101 MB\n",
      "Decreased by 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_tax_registry_b_1.parquet\n",
      "Memory usage of dataframe is 42.26 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 702.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 26.415 MB\n",
      "Decreased by 37.5%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_tax_registry_c_1.parquet\n",
      "Memory usage of dataframe is 127.56 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 259.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 79.723 MB\n",
      "Decreased by 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = train_base_df[['case_id']]\n",
    "variable_type_list = ['train_static_0',\n",
    "                      'train_static_cb_0',\n",
    "                      'train_applprev_1',\n",
    "                      'train_credit_bureau_a_1',\n",
    "                     'train_credit_bureau_b_1',\n",
    "                     'train_debitcard_1',\n",
    "                     'train_deposit_1',\n",
    "                     'train_person_1',\n",
    "                     'train_tax_registry_a_1',\n",
    "                     'train_tax_registry_b_1',\n",
    "                     'train_tax_registry_c_1']\n",
    "for k in variable_type_list:\n",
    "    df_k = multi_merge(train_base_df,'train',k)\n",
    "    df_merged = df_merged.merge(df_k,how = 'outer',on = 'case_id')\n",
    "    del df_k\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "#Merge with Base\n",
    "df_merged_train_depth_1_0 = train_base_df.merge(df_merged,how = 'left',on = 'case_id')\n",
    "del df_merged\n",
    "#Convert date columns to difference\n",
    "date_columns_train_depth_1_0 = [x for x in df_merged_train_depth_1_0.columns if x[-1] == 'D']\n",
    "df_merged_train_depth_1_0 = date_column_depth_0(df_merged_train_depth_1_0)\n",
    "\n",
    "\n",
    "df_merged_train_depth_1_0 = df_merged_train_depth_1_0.drop(columns = date_columns_train_depth_1_0)\n",
    "gc.collect()\n",
    "\n",
    "# df_merged_train_depth_1_0.to_parquet('/kaggle/working/df_merged_train_depth_1_0.parquet')\n",
    "del df_merged_train_depth_1_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_4.parquet\n",
      "Memory usage of dataframe is 3917.61 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3479.457 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_5.parquet\n",
      "Memory usage of dataframe is 4791.42 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 4255.541 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_10.parquet\n",
      "Memory usage of dataframe is 635.80 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 69.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 560.505 MB\n",
      "Decreased by 11.8%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_7.parquet\n",
      "Memory usage of dataframe is 1167.78 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 37.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1037.176 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_6.parquet\n",
      "Memory usage of dataframe is 3698.08 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3284.483 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_3.parquet\n",
      "Memory usage of dataframe is 3850.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3419.997 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_2.parquet\n",
      "Memory usage of dataframe is 2593.82 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2303.722 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_9.parquet\n",
      "Memory usage of dataframe is 2714.09 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2410.541 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_0.parquet\n",
      "Memory usage of dataframe is 767.70 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 76.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 676.792 MB\n",
      "Decreased by 11.8%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_1.parquet\n",
      "Memory usage of dataframe is 1139.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 37.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1012.177 MB\n",
      "Decreased by 11.2%\n",
      "/Users/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_8.parquet\n",
      "Memory usage of dataframe is 2018.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 16.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1793.055 MB\n",
      "Decreased by 11.2%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_merged = train_base_df[['case_id']]\n",
    "df_k = multi_merge(df_merged,'train','train_credit_bureau_a_2')\n",
    "\n",
    "\n",
    "train_bureau = glob.glob(os.path.join(CFG.train_data_path,CFG.train_credit_path))\n",
    "credit_bureau_b_2 = pd.read_parquet(train_bureau)\n",
    "# credit_bureau_b_2 = credit_bureau_b_2[credit_bureau_b_2['num_group1'] == 0 ]\n",
    "credit_bureau_b_2 = credit_bureau_b_2.rename(columns = {'pmts_date_1107D':'record_date','pmts_dpdvalue_108P':'max_dpd'})\n",
    "credit_bureau_b_2 = credit_bureau_b_2.dropna(subset = 'record_date')\n",
    "credit_bureau_b_2 = credit_bureau_b_2[['case_id','record_date','max_dpd']]\n",
    "credit_bureau_b_2['record_date'] = pd.to_datetime(credit_bureau_b_2['record_date'])\n",
    "\n",
    "\n",
    "\n",
    "# df_k = df_k[df_k['num_group1'] == 0 ]\n",
    "df_k = df_k.select_dtypes(exclude=['object'])\n",
    "#Get max record date\n",
    "df_k['record_date'] = pd.to_datetime(df_k[['pmts_year_1139T', 'pmts_year_507T']].max(axis = 1).astype('Int64').astype(str) +  '-'  +df_k[['pmts_month_158T', 'pmts_month_706T']].max(axis = 1).astype('Int64').astype(str) +  '-' +  '1',errors= 'coerce')\n",
    "#Get max dpd\n",
    "df_k['max_dpd'] = df_k[['pmts_dpd_1073P', 'pmts_dpd_303P']].max(axis = 1)\n",
    "df_k = df_k[['case_id','record_date','max_dpd']]\n",
    "df_k = pd.concat([df_k,credit_bureau_b_2],axis = 0)\n",
    "#Merge with base\n",
    "df_k_merged = train_base_df[['case_id','date_decision']].merge(df_k[['case_id','record_date','max_dpd']], how = 'inner', on ='case_id')\n",
    "#Delete df_k\n",
    "del df_k\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "df_k_merged['date_decision'] = pd.to_datetime(df_k_merged['date_decision'])\n",
    "df_k_merged = df_k_merged.assign(\n",
    "    time_diff=\n",
    "    (df_k_merged.date_decision.dt.year - df_k_merged.record_date.dt.year) * 12 +\n",
    "    (df_k_merged.date_decision.dt.month - df_k_merged.record_date.dt.month)\n",
    ")\n",
    "df_k_merged = df_k_merged[df_k_merged['time_diff'] >= 0]\n",
    "df_k_merged['max_dpd'] = df_k_merged['max_dpd'].fillna(0)\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 3),'time_diff_cat'] = '0_3_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 3) & (df_k_merged['time_diff'] <= 6),'time_diff_cat'] = '3_6_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 6) & (df_k_merged['time_diff'] <= 9),'time_diff_cat'] = '6_9_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 9) & (df_k_merged['time_diff'] <= 12),'time_diff_cat'] = '9_12_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 12) & (df_k_merged['time_diff'] <= 18),'time_diff_cat'] = '12_18_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 18) & (df_k_merged['time_diff'] <= 24),'time_diff_cat'] = '18_24_months'\n",
    "\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 3),'time_diff_cat'] = '0_3_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 3) & (df_k_merged['time_diff'] <= 6),'time_diff_cat'] = '3_6_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 6) & (df_k_merged['time_diff'] <= 9),'time_diff_cat'] = '6_9_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 6),'time_diff_cat'] = '0_6_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 12),'time_diff_cat'] = '0_12_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 24),'time_diff_cat'] = '0_24_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 24),'time_diff_cat'] = '24_months'\n",
    "df_k_pivot = pd.pivot_table(df_k_merged,index = 'case_id', columns = 'time_diff_cat',values = 'max_dpd',aggfunc= {'max','min','mean','median'})\n",
    "del df_k_merged\n",
    "gc.collect()\n",
    "\n",
    "df_k_pivot.columns = [f'{i}_{j}' if j != '' else f'{i}' for i,j in df_k_pivot.columns]\n",
    "df_k_pivot = df_k_pivot.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_k_pivot.to_parquet('/kaggle/working/df_merged_train_depth_2_v2.parquet')\n",
    "del df_k_pivot\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train_depth_1_0 = pd.read_parquet('/kaggle/input/efficient-data-read-only-pandas-lgbm/df_merged_train_depth_1_0.parquet')\n",
    "df_merged_train_depth_2 = pd.read_parquet('/kaggle/input/efficient-data-read-only-pandas-lgbm/df_merged_train_depth_2_v2.parquet')\n",
    "df_merged_train_depth_1_0 = reduce_mem_usage(df_merged_train_depth_1_0)\n",
    "df_merged_train_depth_2 = reduce_mem_usage(df_merged_train_depth_2)\n",
    "df_merged_train = df_merged_train_depth_1_0.merge(df_merged_train_depth_2,how = 'left',on=  'case_id')\n",
    "del df_merged_train_depth_1_0\n",
    "del df_merged_train_depth_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Missialue\n",
    "num_cols = df_merged_train.select_dtypes(include=np.number).columns\n",
    "df_merged_train[num_cols] = df_merged_train[num_cols].fillna(0)\n",
    "\n",
    "object_cols = df_merged_train.select_dtypes(include='object').columns\n",
    "df_merged_train[object_cols] = df_merged_train[object_cols].fillna('Mis')\n",
    "df_merged_train = df_merged_train.drop_duplicates(subset= 'case_id')    \n",
    "    \n",
    "#Reindexing\n",
    "identifier_cols = ['date_decision','MONTH']\n",
    "target = 'target'\n",
    "# Reindex\n",
    "df_merged_train = df_merged_train.set_index(['case_id','WEEK_NUM']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X,y\n",
    "X = df_merged_train.drop(columns = identifier_cols + [target])\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "y = df_merged_train['target']\n",
    "#Delete data\n",
    "del df_merged_train\n",
    "gc.collect()\n",
    "#Pick some weeks from starting and some weeks from end as OOT\n",
    "oot_weeks = [0,  1,  2,  3, \n",
    "                        48, 49, 50, 51, 52,\n",
    "                        87, 88, 89,90, 91]\n",
    "#oot df\n",
    "X_oot = X[X.index.isin(oot_weeks,level = 1)]\n",
    "y_oot = y[y.index.isin(oot_weeks,level = 1)]\n",
    "\n",
    "#training df\n",
    "X = X[~X.index.isin(oot_weeks,level = 1)]\n",
    "y = y[~y.index.isin(oot_weeks,level = 1)]\n",
    "\n",
    "\n",
    "#Train test split(stratified with WEEK_NUM in index 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, stratify= list(X.index.get_level_values(1)) , random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val,stratify= list(X_val.index.get_level_values(1)) ,test_size=0.50, random_state=42)\n",
    "#delete\n",
    "del X,y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_data(file_path):\n",
    "    for file in file_path:\n",
    "        file_name = os.path.basename(file)\n",
    "        df = pl.read_parquet(file)\n",
    "        print(f\"ファイル名: {file_name}\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ファイル名: train_applprev_2.parquet\n",
      "shape: (14_075_487, 6)\n",
      "┌─────────┬─────────────────────┬──────────────────┬─────────────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ cacccardblochreas_1 ┆ conts_type_509L  ┆ credacc_cards_statu ┆ num_group1 ┆ num_group2 │\n",
      "│ ---     ┆ 47M                 ┆ ---              ┆ s_52L               ┆ ---        ┆ ---        │\n",
      "│ i64     ┆ ---                 ┆ str              ┆ ---                 ┆ i64        ┆ i64        │\n",
      "│         ┆ str                 ┆                  ┆ str                 ┆            ┆            │\n",
      "╞═════════╪═════════════════════╪══════════════════╪═════════════════════╪════════════╪════════════╡\n",
      "│ 2       ┆ null                ┆ EMPLOYMENT_PHONE ┆ null                ┆ 1          ┆ 1          │\n",
      "│ 2       ┆ null                ┆ EMPLOYMENT_PHONE ┆ null                ┆ 0          ┆ 1          │\n",
      "│ 2       ┆ null                ┆ PRIMARY_MOBILE   ┆ null                ┆ 0          ┆ 0          │\n",
      "│ 2       ┆ null                ┆ PRIMARY_MOBILE   ┆ null                ┆ 1          ┆ 0          │\n",
      "│ 3       ┆ null                ┆ PRIMARY_MOBILE   ┆ null                ┆ 0          ┆ 1          │\n",
      "│ …       ┆ …                   ┆ …                ┆ …                   ┆ …          ┆ …          │\n",
      "│ 2703454 ┆ a55475b1            ┆ PRIMARY_MOBILE   ┆ null                ┆ 0          ┆ 0          │\n",
      "│ 2703454 ┆ a55475b1            ┆ null             ┆ null                ┆ 1          ┆ 3          │\n",
      "│ 2703454 ┆ a55475b1            ┆ null             ┆ null                ┆ 0          ┆ 1          │\n",
      "│ 2703454 ┆ a55475b1            ┆ PRIMARY_MOBILE   ┆ null                ┆ 1          ┆ 0          │\n",
      "│ 2703454 ┆ a55475b1            ┆ HOME_PHONE       ┆ null                ┆ 1          ┆ 1          │\n",
      "└─────────┴─────────────────────┴──────────────────┴─────────────────────┴────────────┴────────────┘\n",
      "ファイル名: train_applprev_1_0.parquet\n",
      "shape: (3_887_684, 41)\n",
      "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ case_id ┆ actualdpd_ ┆ annuity_8 ┆ approvald ┆ … ┆ rejectrea ┆ revolving ┆ status_21 ┆ tenor_203 │\n",
      "│ ---     ┆ 943P       ┆ 53A       ┆ ate_319D  ┆   ┆ sonclient ┆ account_3 ┆ 9L        ┆ L         │\n",
      "│ i64     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ _4145042M ┆ 94A       ┆ ---       ┆ ---       │\n",
      "│         ┆ f64        ┆ f64       ┆ str       ┆   ┆ ---       ┆ ---       ┆ str       ┆ f64       │\n",
      "│         ┆            ┆           ┆           ┆   ┆ str       ┆ f64       ┆           ┆           │\n",
      "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 2       ┆ 0.0        ┆ 640.2     ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ D         ┆ 24.0      │\n",
      "│ 2       ┆ 0.0        ┆ 1682.4    ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ D         ┆ 12.0      │\n",
      "│ 3       ┆ 0.0        ┆ 6140.0    ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ D         ┆ 12.0      │\n",
      "│ 4       ┆ 0.0        ┆ 2556.6    ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ T         ┆ 24.0      │\n",
      "│ 5       ┆ 0.0        ┆ null      ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ T         ┆ null      │\n",
      "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ 2651092 ┆ 0.0        ┆ 0.0       ┆ null      ┆ … ┆ P94_109_1 ┆ null      ┆ D         ┆ null      │\n",
      "│         ┆            ┆           ┆           ┆   ┆ 43        ┆           ┆           ┆           │\n",
      "│ 2651092 ┆ 0.0        ┆ 4366.0    ┆ 2017-11-0 ┆ … ┆ a55475b1  ┆ null      ┆ K         ┆ 5.0       │\n",
      "│         ┆            ┆           ┆ 9         ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 2651092 ┆ 0.0        ┆ 2632.2    ┆ 2015-12-1 ┆ … ┆ a55475b1  ┆ null      ┆ K         ┆ 14.0      │\n",
      "│         ┆            ┆           ┆ 1         ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 2651092 ┆ 0.0        ┆ null      ┆ 2014-02-1 ┆ … ┆ a55475b1  ┆ 6.80531e8 ┆ K         ┆ null      │\n",
      "│         ┆            ┆           ┆ 5         ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 2651092 ┆ 0.0        ┆ 3119.2    ┆ 2012-12-1 ┆ … ┆ a55475b1  ┆ null      ┆ K         ┆ 12.0      │\n",
      "│         ┆            ┆           ┆ 2         ┆   ┆           ┆           ┆           ┆           │\n",
      "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "ファイル名: train_applprev_1_1.parquet\n",
      "shape: (2_638_295, 41)\n",
      "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ case_id ┆ actualdpd_ ┆ annuity_8 ┆ approvald ┆ … ┆ rejectrea ┆ revolving ┆ status_21 ┆ tenor_203 │\n",
      "│ ---     ┆ 943P       ┆ 53A       ┆ ate_319D  ┆   ┆ sonclient ┆ account_3 ┆ 9L        ┆ L         │\n",
      "│ i64     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ _4145042M ┆ 94A       ┆ ---       ┆ ---       │\n",
      "│         ┆ f64        ┆ f64       ┆ str       ┆   ┆ ---       ┆ ---       ┆ str       ┆ f64       │\n",
      "│         ┆            ┆           ┆           ┆   ┆ str       ┆ f64       ┆           ┆           │\n",
      "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 40704   ┆ 0.0        ┆ 7204.6    ┆ null      ┆ … ┆ P94_109_1 ┆ null      ┆ D         ┆ 12.0      │\n",
      "│         ┆            ┆           ┆           ┆   ┆ 43        ┆           ┆           ┆           │\n",
      "│ 40734   ┆ 0.0        ┆ 3870.2    ┆ null      ┆ … ┆ P94_109_1 ┆ null      ┆ D         ┆ 18.0      │\n",
      "│         ┆            ┆           ┆           ┆   ┆ 43        ┆           ┆           ┆           │\n",
      "│ 40737   ┆ 0.0        ┆ 2324.4001 ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ D         ┆ 18.0      │\n",
      "│ 40791   ┆ 0.0        ┆ 3044.4001 ┆ null      ┆ … ┆ P94_109_1 ┆ null      ┆ D         ┆ 24.0      │\n",
      "│         ┆            ┆           ┆           ┆   ┆ 43        ┆           ┆           ┆           │\n",
      "│ 40791   ┆ 0.0        ┆ 2320.8    ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ D         ┆ 12.0      │\n",
      "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ 2703453 ┆ 0.0        ┆ 927.8     ┆ 2014-01-2 ┆ … ┆ a55475b1  ┆ null      ┆ K         ┆ 18.0      │\n",
      "│         ┆            ┆           ┆ 2         ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 2703453 ┆ 0.0        ┆ 266.80002 ┆ 2013-06-2 ┆ … ┆ a55475b1  ┆ null      ┆ K         ┆ 12.0      │\n",
      "│         ┆            ┆           ┆ 9         ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 2703453 ┆ 0.0        ┆ 416.2     ┆ null      ┆ … ┆ a55475b1  ┆ null      ┆ D         ┆ 6.0       │\n",
      "│ 2703454 ┆ 0.0        ┆ 2986.8    ┆ 2020-06-2 ┆ … ┆ a55475b1  ┆ null      ┆ A         ┆ 6.0       │\n",
      "│         ┆            ┆           ┆ 1         ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 2703454 ┆ 0.0        ┆ 6726.6    ┆ 2019-08-0 ┆ … ┆ a55475b1  ┆ null      ┆ K         ┆ 12.0      │\n",
      "│         ┆            ┆           ┆ 1         ┆   ┆           ┆           ┆           ┆           │\n",
      "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "file_path = glob.glob(os.path.join(CFG.train_data_path,CFG.train_applprev_path))\n",
    "investigate_data(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
