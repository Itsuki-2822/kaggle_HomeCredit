{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "import  gc\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    home_directory = os.path.expanduser('~/kaggle_HomeCredit/parquet_files/')\n",
    "    train_data_path = os.path.join(home_directory, 'train/')\n",
    "    test_data_path = os.path.join(home_directory, 'test/')\n",
    "    \n",
    "    train_applprev_path = 'train_applprev_*.parquet'\n",
    "    train_base_path =  'train_base.parquet'\n",
    "    train_credit_path = 'train_credit_bureau_*.parquet'\n",
    "    train_debitcard_path = 'train_debitcard_1.parquet'\n",
    "    train_deposit_path = 'train_deposit_1.parquet'\n",
    "    train_other_path = 'train_other_1.parquet'\n",
    "    train_person_path = 'train_person_*.parquet'\n",
    "    train_static_path = 'train_static_*.parquet'\n",
    "    train_tax__path = 'train_tax_registry_*.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def reduce_mem_usage(df, int_cast=True, obj_to_category=False, subset=None):\n",
    "    \"\"\"\n",
    "    1. メモリ使用量のチェック\n",
    "    2. データ型の確認と変更\n",
    "    3. メモリ使用量の再計算と削減効果の表示\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    gc.collect()\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "#     cols_none = subset if subset is  None else df.columns.tolist()\n",
    "#     for col_non in tqdm(cols_none):\n",
    "#         df[col_non] = df[col_non].fillna(-888)\n",
    "    \n",
    "    cols = subset if subset is not None else df.columns.tolist()\n",
    "\n",
    "    for col in tqdm(cols):\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "#             df[col] = df[col].fillna(-888)\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "#             # test if column can be converted to an integer\n",
    "#             treat_as_int = str(col_type)[:3] == 'int'\n",
    "#             if int_cast and not treat_as_int:\n",
    "#                 treat_as_int = check_if_integer(df[col])\n",
    "                \n",
    "            treat_as_int = True\n",
    "            if treat_as_int:\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "                    df[col] = df[col].astype(np.uint8, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "                    df[col] = df[col].astype(np.uint16, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "                    df[col] = df[col].astype(np.uint32, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64, errors='ignore')\n",
    "                elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "                    df[col] = df[col].astype(np.uint64, errors='ignore')\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16, errors='ignore')\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32, errors='ignore')\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64, errors='ignore')\n",
    "        elif 'datetime' not in col_type.name and obj_to_category:\n",
    "            df[col] = df[col].fillna('Mis')\n",
    "            df[col] = df[col].astype('category')\n",
    "    gc.collect()\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "def date_column_depth_0(df):\n",
    "    \"\"\"\n",
    "    1. 特定の命名規則に基づいて日付列を特定\n",
    "    2. それらを日付型に変換します。\n",
    "    3. 'date_decision'列と他の日付列との差分（日数）を計算し、新しい列としてデータフレームに追加します。\n",
    "    \"\"\"\n",
    "    date_columns = ['date_decision'] + [x for x in df.columns if x[-1] == 'D'] \n",
    "    df[date_columns] = df[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "    df_diff = df[date_columns].apply(lambda col: (df['date_decision'] - col).dt.days)\n",
    "    df_diff.columns = [f'Diff_{col}' for col in df_diff.columns]\n",
    "    df = pd.concat([df, df_diff], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def union_parquest(list_parq):\n",
    "    \"\"\"\n",
    "    1. 指定されたParquetファイルのリストからデータフレームの読み込み\n",
    "    2. 各データフレームにreduce_mem_usage関数を適用し、メモリ使用量を削減します。\n",
    "    3. これらのデータフレームを結合し、再度メモリ使用量の削減を試みます。\n",
    "    \"\"\"\n",
    "    df_list = [reduce_mem_usage(pd.read_parquet(i)) for i in list_parq]\n",
    "    union_df = pd.concat(df_list)\n",
    "    union_df = reduce_mem_usage(union_df)\n",
    "    return union_df   \n",
    "\n",
    "def gini(x):\n",
    "    \"\"\"\n",
    "    配列内の各値に対して、他の全ての値との差の絶対値を計算し、これらの差の総和を求めます。\n",
    "    この総和を配列の長さの2乗と配列の平均値の積で正規化し、Gini係数を計算します。\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        total += np.sum(np.abs(xi - x[i:]))\n",
    "    return total / (len(x)**2 * np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge(base_data,train_vs_test,data_type):\n",
    "    \"\"\"\n",
    "    1. train_vs_test変数をチェックし、'train'または'test'のいずれかに基づいて、\n",
    "        対応するデータセットのファイルパスをCFG設定から取得します。\n",
    "    2. 'num_group1' カラムが存在する場合に限り、そのカラムの値が 0 である行のみを保持し、\n",
    "        そのカラムをデータフレームから削除する処理を行っています。\n",
    "    3. 読み込んだデータフレームを先に作成した空のデータフレームに結合します\n",
    "    \"\"\"\n",
    "    if train_vs_test ==  'train':\n",
    "        file_path = CFG.train_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    elif train_vs_test ==  'test':\n",
    "        file_path = CFG.test_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    df_i_merged = pd.DataFrame()\n",
    "    \n",
    "    for i in list_parq:\n",
    "        print(i)\n",
    "        df_i = pd.read_parquet(i)\n",
    "        df_i = reduce_mem_usage(df_i)\n",
    "        if 'num_group1' in df_i.columns: \n",
    "            df_i = df_i[df_i['num_group1'] == 0 ]\n",
    "            df_i = df_i.drop(columns = 'num_group1')\n",
    "    #         df_i_merged = df_i_merged.merge(df_i,how = 'left',on = 'case_id')\n",
    "        df_i_merged = pd.concat([df_i_merged,df_i])\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    return df_i_merged        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge_v2(base_data,train_vs_test,data_type):\n",
    "    \"\"\"\n",
    "    1. train_vs_test変数をチェックし、'train'または'test'のいずれかに基づいて、\n",
    "        対応するデータセットのファイルパスをCFG設定から取得します。\n",
    "    2. ファイルパスのlistを読み込みnum_group1のカラムを削除する\n",
    "    3. 読み込んだデータフレームを先に作成した空のデータフレームに結合します\n",
    "    \"\"\"\n",
    "    if train_vs_test ==  'train':\n",
    "        file_path = CFG.train_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    elif train_vs_test ==  'test':\n",
    "        file_path = CFG.test_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    df_i_merged = pd.DataFrame()\n",
    "    \n",
    "    for i in list_parq:\n",
    "        print(i)\n",
    "        df_i = pd.read_parquet(i)\n",
    "        df_i = reduce_mem_usage(df_i)\n",
    "        if 'num_group1' in df_i.columns: \n",
    "#             df_i = df_i[df_i['num_group1'] == 0 ]\n",
    "            df_i = df_i.drop(columns = 'num_group1')\n",
    "    #         df_i_merged = df_i_merged.merge(df_i,how = 'left',on = 'case_id')\n",
    "        df_i_merged = pd.concat([df_i_merged,df_i])\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    return df_i_merged        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_merge_depth_2(base_data,train_vs_test,data_type):\n",
    "    \"\"\"\n",
    "    1. train_vs_test変数をチェックし、'train'または'test'のいずれかに基づいて、\n",
    "        対応するデータセットのファイルパスをCFG設定から取得します。\n",
    "    2. num_group1列が存在する場合、その値が0である行のみを残します。\n",
    "        オブジェクト型の列を除外し、残った数値型のデータに対してピボットテーブルを作成します。\n",
    "        このピボットテーブルでは、case_idをインデックスにして、各数値型の列に対して最大値（max）と最小値（min）の集計関数を適用します。\n",
    "        集計後の列名を再構成し、num_groupを含む任意の列を削除します。\n",
    "    3.\n",
    "    \"\"\"\n",
    "    if train_vs_test ==  'train':\n",
    "        file_path = CFG.train_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    elif train_vs_test ==  'test':\n",
    "        file_path = CFG.test_data_path\n",
    "        list_parq =  [file_path + '/' + i for i in os.listdir(file_path) if data_type in i ] \n",
    "        \n",
    "    df_i_merged = pd.DataFrame()\n",
    "    \n",
    "    for i in list_parq:\n",
    "        print(i)\n",
    "        df_i = pd.read_parquet(i)\n",
    "        df_i = reduce_mem_usage(df_i)\n",
    "        if 'num_group1' in df_i.columns: \n",
    "            df_i = df_i[df_i['num_group1'] == 0 ]\n",
    "            df_i = df_i.select_dtypes(exclude=['object'])\n",
    "            df_i = pd.pivot_table(df_i,index = 'case_id', aggfunc= {'max','min'})\n",
    "            df_i.columns = [f'{j}_{i}' if j != '' else f'{i}' for i,j in df_i.columns]\n",
    "            df_i = df_i.drop(columns = [ i for i in df_i.columns if 'num_group' in i])\n",
    "        df_i_merged = pd.concat([df_i_merged,df_i])\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    return df_i_merged        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 58.24 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 661.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 26.207 MB\n",
      "Decreased by 55.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_base_df = pd.read_parquet(CFG.train_data_path + CFG.train_base_path)\n",
    "train_base_df = reduce_mem_usage(train_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_static_0_0.parquet\n",
      "Memory usage of dataframe is 1279.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [00:00<00:00, 275.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1045.325 MB\n",
      "Decreased by 18.3%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_static_0_1.parquet\n",
      "Memory usage of dataframe is 666.73 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [00:00<00:00, 563.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 547.050 MB\n",
      "Decreased by 18.0%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_static_cb_0.parquet\n",
      "Memory usage of dataframe is 606.73 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 192.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 601.006 MB\n",
      "Decreased by 0.9%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_applprev_1_1.parquet\n",
      "Memory usage of dataframe is 825.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 121.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 797.596 MB\n",
      "Decreased by 3.4%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_applprev_1_0.parquet\n",
      "Memory usage of dataframe is 1216.09 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 80.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1175.304 MB\n",
      "Decreased by 3.4%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_1.parquet\n",
      "Memory usage of dataframe is 3621.87 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 34.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3564.565 MB\n",
      "Decreased by 1.6%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_0.parquet\n",
      "Memory usage of dataframe is 2476.11 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 56.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2436.932 MB\n",
      "Decreased by 1.6%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_2.parquet\n",
      "Memory usage of dataframe is 2256.48 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 57.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2220.774 MB\n",
      "Decreased by 1.6%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_1_3.parquet\n",
      "Memory usage of dataframe is 1253.25 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 102.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1233.424 MB\n",
      "Decreased by 1.6%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_b_1.parquet\n",
      "Memory usage of dataframe is 29.45 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 1574.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 28.554 MB\n",
      "Decreased by 3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_debitcard_1.parquet\n",
      "Memory usage of dataframe is 7.20 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 1229.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 5.551 MB\n",
      "Decreased by 22.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_deposit_1.parquet\n",
      "Memory usage of dataframe is 5.53 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 2338.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3.459 MB\n",
      "Decreased by 37.5%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_person_1.parquet\n",
      "Memory usage of dataframe is 839.52 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 349.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 808.322 MB\n",
      "Decreased by 3.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_tax_registry_a_1.parquet\n",
      "Memory usage of dataframe is 124.96 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 237.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 78.101 MB\n",
      "Decreased by 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_tax_registry_b_1.parquet\n",
      "Memory usage of dataframe is 42.26 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 723.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 26.415 MB\n",
      "Decreased by 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_tax_registry_c_1.parquet\n",
      "Memory usage of dataframe is 127.56 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 227.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 79.723 MB\n",
      "Decreased by 37.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = train_base_df[['case_id']]\n",
    "variable_type_list = ['train_static_0',\n",
    "                      'train_static_cb_0',\n",
    "                      'train_applprev_1',\n",
    "                      'train_credit_bureau_a_1',\n",
    "                     'train_credit_bureau_b_1',\n",
    "                     'train_debitcard_1',\n",
    "                     'train_deposit_1',\n",
    "                     'train_person_1',\n",
    "                     'train_tax_registry_a_1',\n",
    "                     'train_tax_registry_b_1',\n",
    "                     'train_tax_registry_c_1']\n",
    "for k in variable_type_list:\n",
    "    df_k = multi_merge(train_base_df,'train',k)\n",
    "    df_merged = df_merged.merge(df_k,how = 'outer',on = 'case_id')\n",
    "    del df_k\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "#Merge with Base\n",
    "df_merged_train_depth_1_0 = train_base_df.merge(df_merged,how = 'left',on = 'case_id')\n",
    "del df_merged\n",
    "#Convert date columns to difference\n",
    "date_columns_train_depth_1_0 = [x for x in df_merged_train_depth_1_0.columns if x[-1] == 'D']\n",
    "df_merged_train_depth_1_0 = date_column_depth_0(df_merged_train_depth_1_0)\n",
    "\n",
    "\n",
    "df_merged_train_depth_1_0 = df_merged_train_depth_1_0.drop(columns = date_columns_train_depth_1_0)\n",
    "gc.collect()\n",
    "\n",
    "df_merged_train_depth_1_0.to_parquet(CFG.train_data_path+'df_merged_train_depth_1_0.parquet')\n",
    "del df_merged_train_depth_1_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_2.parquet\n",
      "Memory usage of dataframe is 2593.82 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2303.722 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_8.parquet\n",
      "Memory usage of dataframe is 2018.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1793.055 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_3.parquet\n",
      "Memory usage of dataframe is 3850.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3419.997 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_6.parquet\n",
      "Memory usage of dataframe is 3698.08 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3284.483 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_7.parquet\n",
      "Memory usage of dataframe is 1167.78 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 39.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1037.176 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_10.parquet\n",
      "Memory usage of dataframe is 635.80 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 73.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 560.505 MB\n",
      "Decreased by 11.8%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_4.parquet\n",
      "Memory usage of dataframe is 3917.61 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3479.457 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_0.parquet\n",
      "Memory usage of dataframe is 767.70 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 67.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 676.792 MB\n",
      "Decreased by 11.8%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_5.parquet\n",
      "Memory usage of dataframe is 4791.42 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 4255.541 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_9.parquet\n",
      "Memory usage of dataframe is 2714.09 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2410.541 MB\n",
      "Decreased by 11.2%\n",
      "/home/i.itsuki/kaggle_HomeCredit/parquet_files/train//train_credit_bureau_a_2_1.parquet\n",
      "Memory usage of dataframe is 1139.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1012.177 MB\n",
      "Decreased by 11.2%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['pmtyyhs_dpd_303P'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m df_k[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_k[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpmts_year_1139T\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpmts_year_507T\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmax(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInt64\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;241m+\u001b[39mdf_k[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpmts_month_158T\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpmts_month_706T\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmax(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInt64\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m,errors\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Get max dpd\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df_k[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_dpd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_k\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpmts_dpd_1073P\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpmtyyhs_dpd_303P\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmax(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m df_k \u001b[38;5;241m=\u001b[39m df_k[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord_date\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_dpd\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     22\u001b[0m df_k \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_k,credit_bureau_b_2],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/kaggle_HomeCredit/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/kaggle_HomeCredit/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_HomeCredit/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['pmtyyhs_dpd_303P'] not in index\""
     ]
    }
   ],
   "source": [
    "df_merged = train_base_df[['case_id']]\n",
    "df_k = multi_merge(df_merged,'train','train_credit_bureau_a_2')\n",
    "\n",
    "\n",
    "train_bureau = glob.glob(os.path.join(CFG.train_data_path,CFG.train_credit_path))\n",
    "credit_bureau_b_2 = pd.read_parquet(train_bureau)\n",
    "# credit_bureau_b_2 = credit_bureau_b_2[credit_bureau_b_2['num_group1'] == 0 ]\n",
    "credit_bureau_b_2 = credit_bureau_b_2.rename(columns = {'pmts_date_1107D':'record_date','pmts_dpdvalue_108P':'max_dpd'})\n",
    "credit_bureau_b_2 = credit_bureau_b_2.dropna(subset = 'record_date')\n",
    "credit_bureau_b_2 = credit_bureau_b_2[['case_id','record_date','max_dpd']]\n",
    "credit_bureau_b_2['record_date'] = pd.to_datetime(credit_bureau_b_2['record_date'])\n",
    "\n",
    "\n",
    "\n",
    "# df_k = df_k[df_k['num_group1'] == 0 ]\n",
    "df_k = df_k.select_dtypes(exclude=['object'])\n",
    "#Get max record date\n",
    "df_k['record_date'] = pd.to_datetime(df_k[['pmts_year_1139T', 'pmts_year_507T']].max(axis = 1).astype('Int64').astype(str) +  '-'  +df_k[['pmts_month_158T', 'pmts_month_706T']].max(axis = 1).astype('Int64').astype(str) +  '-' +  '1',errors= 'coerce')\n",
    "#Get max dpd\n",
    "df_k['max_dpd'] = df_k[['pmts_dpd_1073P', 'pmtyyhs_dpd_303P']].max(axis = 1)\n",
    "df_k = df_k[['case_id','record_date','max_dpd']]\n",
    "df_k = pd.concat([df_k,credit_bureau_b_2],axis = 0)\n",
    "#Merge with base\n",
    "df_k_merged = train_base_df[['case_id','date_decision']].merge(df_k[['case_id','record_date','max_dpd']], how = 'inner', on ='case_id')\n",
    "#Delete df_k\n",
    "del df_k\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "df_k_merged['date_decision'] = pd.to_datetime(df_k_merged['date_decision'])\n",
    "df_k_merged = df_k_merged.assign(\n",
    "    time_diff=\n",
    "    (df_k_merged.date_decision.dt.year - df_k_merged.record_date.dt.year) * 12 +\n",
    "    (df_k_merged.date_decision.dt.month - df_k_merged.record_date.dt.month)\n",
    ")\n",
    "df_k_merged = df_k_merged[df_k_merged['time_diff'] >= 0]\n",
    "df_k_merged['max_dpd'] = df_k_merged['max_dpd'].fillna(0)\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 3),'time_diff_cat'] = '0_3_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 3) & (df_k_merged['time_diff'] <= 6),'time_diff_cat'] = '3_6_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 6) & (df_k_merged['time_diff'] <= 9),'time_diff_cat'] = '6_9_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 9) & (df_k_merged['time_diff'] <= 12),'time_diff_cat'] = '9_12_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 12) & (df_k_merged['time_diff'] <= 18),'time_diff_cat'] = '12_18_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 18) & (df_k_merged['time_diff'] <= 24),'time_diff_cat'] = '18_24_months'\n",
    "\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 3),'time_diff_cat'] = '0_3_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 3) & (df_k_merged['time_diff'] <= 6),'time_diff_cat'] = '3_6_months'\n",
    "# df_k_merged.loc[(df_k_merged['time_diff'] > 6) & (df_k_merged['time_diff'] <= 9),'time_diff_cat'] = '6_9_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 6),'time_diff_cat'] = '0_6_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 12),'time_diff_cat'] = '0_12_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 0) & (df_k_merged['time_diff'] <= 24),'time_diff_cat'] = '0_24_months'\n",
    "df_k_merged.loc[(df_k_merged['time_diff'] > 24),'time_diff_cat'] = '24_months'\n",
    "df_k_pivot = pd.pivot_table(df_k_merged,index = 'case_id', columns = 'time_diff_cat',values = 'max_dpd',aggfunc= {'max','min','mean','median'})\n",
    "del df_k_merged\n",
    "gc.collect()\n",
    "\n",
    "df_k_pivot.columns = [f'{i}_{j}' if j != '' else f'{i}' for i,j in df_k_pivot.columns]\n",
    "df_k_pivot = df_k_pivot.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k_pivot.to_parquet(CFG.train_data_path+'df_merged_train_depth_2_v2.parquet')\n",
    "del df_k_pivot\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 4680.83 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:02<00:00, 165.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 4625.507 MB\n",
      "Decreased by 1.2%\n",
      "Memory usage of dataframe is 89.93 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 251.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 47.612 MB\n",
      "Decreased by 47.1%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_train_depth_1_0 = pd.read_parquet(CFG.train_data_path+'df_merged_train_depth_1_0.parquet')\n",
    "df_merged_train_depth_2 = pd.read_parquet(CFG.train_data_path+'df_merged_train_depth_2_v2.parquet')\n",
    "df_merged_train_depth_1_0 = reduce_mem_usage(df_merged_train_depth_1_0)\n",
    "df_merged_train_depth_2 = reduce_mem_usage(df_merged_train_depth_2)\n",
    "df_merged_train = df_merged_train_depth_1_0.merge(df_merged_train_depth_2,how = 'left',on=  'case_id')\n",
    "del df_merged_train_depth_1_0\n",
    "del df_merged_train_depth_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged_train.to_parquet(CFG.train_data_path+'df_merged_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Missialue\n",
    "num_cols = df_merged_train.select_dtypes(include=np.number).columns\n",
    "df_merged_train[num_cols] = df_merged_train[num_cols].fillna(0)\n",
    "\n",
    "object_cols = df_merged_train.select_dtypes(include='object').columns\n",
    "df_merged_train[object_cols] = df_merged_train[object_cols].fillna('Mis')\n",
    "df_merged_train = df_merged_train.drop_duplicates(subset= 'case_id')    \n",
    "    \n",
    "#Reindexing\n",
    "identifier_cols = ['date_decision','MONTH']\n",
    "target = 'target'\n",
    "# Reindex\n",
    "df_merged_train = df_merged_train.set_index(['case_id','WEEK_NUM']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define X,y\n",
    "X = df_merged_train.drop(columns = identifier_cols + [target])\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "y = df_merged_train['target']\n",
    "#Delete data\n",
    "del df_merged_train\n",
    "gc.collect()\n",
    "#Pick some weeks from starting and some weeks from end as OOT\n",
    "oot_weeks = [0,  1,  2,  3, \n",
    "                        48, 49, 50, 51, 52,\n",
    "                        87, 88, 89,90, 91]\n",
    "#oot df\n",
    "X_oot = X[X.index.isin(oot_weeks,level = 1)]\n",
    "y_oot = y[y.index.isin(oot_weeks,level = 1)]\n",
    "\n",
    "#training df\n",
    "X = X[~X.index.isin(oot_weeks,level = 1)]\n",
    "y = y[~y.index.isin(oot_weeks,level = 1)]\n",
    "\n",
    "\n",
    "#Train test split(stratified with WEEK_NUM in index 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, stratify= list(X.index.get_level_values(1)) , random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val,stratify= list(X_val.index.get_level_values(1)) ,test_size=0.50, random_state=42)\n",
    "#delete\n",
    "del X,y\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
