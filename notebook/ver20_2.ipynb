{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:43.545610Z","iopub.status.busy":"2024-05-15T00:26:43.545138Z","iopub.status.idle":"2024-05-15T00:26:47.864324Z","shell.execute_reply":"2024-05-15T00:26:47.862886Z","shell.execute_reply.started":"2024-05-15T00:26:43.545575Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mira/kaggle_HomeCredit/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# 標準ライブラリ\n","import gc\n","import os\n","import pickle\n","import random\n","import sys\n","import warnings\n","from itertools import combinations, permutations\n","from pathlib import Path\n","import pytz\n","\n","\n","# サードパーティのライブラリ\n","import category_encoders as ce\n","import joblib\n","import lightgbm as lgb\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","import scipy as sp\n","import seaborn as sns\n","import xgboost as xgb\n","from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n","from dateutil.relativedelta import relativedelta\n","from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\n","from sklearn.model_selection import (GroupKFold, KFold, StratifiedKFold,\n","                                     StratifiedGroupKFold, TimeSeriesSplit,\n","                                     train_test_split)\n","from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n","\n","from tqdm.auto import tqdm\n","from sklearn.linear_model import LogisticRegression\n","\n","import matplotlib.pyplot as plt\n","\n","\n","\n","warnings.filterwarnings('ignore')\n","\n","\n","from catboost import CatBoostClassifier, Pool  # type: ignore\n","from glob import glob\n","from IPython.display import display  # type: ignore\n","from pathlib import Path\n","from sklearn.base import BaseEstimator, ClassifierMixin  # type: ignore\n","from sklearn.metrics import roc_auc_score  # type: ignore\n","from sklearn.model_selection import StratifiedGroupKFold  # type: ignore\n","from typing import Any\n","import datetime"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class CFG:\n","    home_directory = os.path.expanduser('~/kaggle_HomeCredit/')\n","    kaggle_directory = os.path.expanduser('/kaggle/input/home-credit-credit-risk-model-stability/')\n","    \n","    train_data_path = os.path.join(home_directory, 'train/')\n","    test_data_path = os.path.join(home_directory, 'test/')\n","    \n","    OOF_DATA_PATH = Path(home_directory) / 'oof'\n","    MODEL_DATA_PATH = Path(home_directory) / 'models'\n","    SUB_DATA_PATH = Path(home_directory) / 'submission'\n","\n","    def __init__(self):\n","        self.create_directories()\n","    \n","    def create_directories(self):\n","        for path in [self.OOF_DATA_PATH, self.MODEL_DATA_PATH, self.SUB_DATA_PATH]:\n","            path.mkdir(parents=True, exist_ok=True)\n","    \n","    \n","    VER = 20_2\n","    AUTHOR = 'Mira'\n","    COMPETITION = 'HomeCredit'\n","\n","    METHOD_LIST = ['lightgbm','catboost']\n","    #METHOD_LIST = ['lightgbm']\n","    seed = 28\n","    n_folds = 5\n","    target_col = 'target'\n","    metric = 'auc'\n","    \n","    metric_maximize_flag = True\n","    num_boost_round = 500\n","    early_stopping_round = 200\n","    verbose = 25\n","    classification_lgb_params = {\n","        \"boosting_type\": \"gbdt\",\n","        \"objective\": \"binary\",\n","        \"metric\": \"auc\",\n","        \"max_depth\": 10,  \n","        \"learning_rate\": 0.05,\n","        \"n_estimators\": num_boost_round,  \n","        \"colsample_bytree\": 0.8,\n","        \"colsample_bynode\": 0.8,\n","        \"verbose\": -1,\n","        \"reg_alpha\": 0.1,\n","        \"reg_lambda\": 10,\n","        \"extra_trees\":True,\n","        'num_leaves':64,\n","        'seed': seed,\n","    }\n","    classification_xgb_params = {\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'logloss',\n","        'learning_rate': 0.05,\n","        'random_state': seed,\n","        \"tree_method\": \"gpu_hist\",\n","    }\n","\n","    classification_cat_params = {\n","        'iterations':num_boost_round,                \n","        'learning_rate':0.05,\n","        'depth':10,                     \n","        'l2_leaf_reg':10,                  \n","        'loss_function':'Logloss',        \n","        'eval_metric':'AUC',              \n","        'bootstrap_type':'Bernoulli',    \n","        'subsample':0.8,                  \n","        'colsample_bylevel':0.8,         \n","        'verbose':False,                  \n","        'leaf_estimation_iterations':10,       \n","        'random_seed':seed,\n","        #\"task_type\": \"GPU\",\n","    }\n","    model_weight_dict = {'lightgbm': 0.5,'catboost':0.5}\n","    #model_weight_dict = {'lightgbm': 1}\n","\n","class is_kaggle:\n","    def __init__(self, Kaggle):\n","        if Kaggle == \"Yes\":\n","            self.path = Path(CFG.kaggle_directory)\n","            CFG.MODEL_DATA_PATH = Path('/kaggle/input/05061800/models')\n","        else:\n","            self.path = Path(CFG.home_directory)\n","            CFG.MODEL_DATA_PATH = Path(CFG.home_directory) / 'models'\n","\n","def create_timestamped_file():\n","    tz_tokyo = pytz.timezone('Asia/Tokyo')\n","    now = datetime.datetime.now(tz=tz_tokyo)\n","    filename = now.strftime('%m%d-%H%M') + '.txt'\n","    full_path = CFG.MODEL_DATA_PATH / filename\n","    full_path.touch()\n","\n","#create_timestamped_file()\n","cfg_instance = CFG()      \n","selector = is_kaggle(\"No\")\n","\n","ROOT = selector.path\n","TRAIN_DIR       = ROOT / \"parquet_files/train\"\n","TEST_DIR        = ROOT / \"parquet_files/test\"\n","SAMPLE_SUB = ROOT / \"sample_submission.csv\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:47.867596Z","iopub.status.busy":"2024-05-15T00:26:47.867113Z","iopub.status.idle":"2024-05-15T00:26:47.908884Z","shell.execute_reply":"2024-05-15T00:26:47.907991Z","shell.execute_reply.started":"2024-05-15T00:26:47.867539Z"},"trusted":true},"outputs":[],"source":["class Utility:\n","    @staticmethod\n","    def get_feat_defs(ending_with: str) -> None:\n","        \"\"\"\n","        Retrieves feature definitions from a CSV file based on the specified ending.\n","\n","        Args:\n","        - ending_with (str): Ending to filter feature definitions.\n","\n","        Returns:\n","        - pl.DataFrame: Filtered feature definitions.\n","        \"\"\"\n","        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n","\n","        filtered_feats: pl.DataFrame = feat_defs.filter(\n","            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n","        )\n","\n","        with pl.Config(fmt_str_lengths=200, tbl_rows=-1):\n","            print(filtered_feats)\n","\n","        filtered_feats = None\n","        feat_defs = None\n","\n","    @staticmethod\n","    def find_index(lst: list[Any], item: Any) -> int | None:\n","        \"\"\"\n","        Finds the index of an item in a list.\n","\n","        Args:\n","        - lst (list): List to search.\n","        - item (Any): Item to find in the list.\n","\n","        Returns:\n","        - int | None: Index of the item if found, otherwise None.\n","        \"\"\"\n","        try:\n","            return lst.index(item)\n","        except ValueError:\n","            return None\n","\n","    @staticmethod\n","    def dtype_to_str(dtype: pl.DataType) -> str:\n","        \"\"\"\n","        Converts Polars data type to string representation.\n","\n","        Args:\n","        - dtype (pl.DataType): Polars data type.\n","\n","        Returns:\n","        - str: String representation of the data type.\n","        \"\"\"\n","        dtype_map = {\n","            pl.Decimal: \"Decimal\",\n","            pl.Float32: \"Float32\",\n","            pl.Float64: \"Float64\",\n","            pl.UInt8: \"UInt8\",\n","            pl.UInt16: \"UInt16\",\n","            pl.UInt32: \"UInt32\",\n","            pl.UInt64: \"UInt64\",\n","            pl.Int8: \"Int8\",\n","            pl.Int16: \"Int16\",\n","            pl.Int32: \"Int32\",\n","            pl.Int64: \"Int64\",\n","            pl.Date: \"Date\",\n","            pl.Datetime: \"Datetime\",\n","            pl.Duration: \"Duration\",\n","            pl.Time: \"Time\",\n","            pl.Array: \"Array\",\n","            pl.List: \"List\",\n","            pl.Struct: \"Struct\",\n","            pl.String: \"String\",\n","            pl.Categorical: \"Categorical\",\n","            pl.Enum: \"Enum\",\n","            pl.Utf8: \"Utf8\",\n","            pl.Binary: \"Binary\",\n","            pl.Boolean: \"Boolean\",\n","            pl.Null: \"Null\",\n","            pl.Object: \"Object\",\n","            pl.Unknown: \"Unknown\",\n","        }\n","\n","        return dtype_map.get(dtype)\n","\n","    @staticmethod\n","    def find_feat_occur(regex_path: str, ending_with: str) -> pl.DataFrame:\n","        \"\"\"\n","        Finds occurrences of features ending with a specific string in Parquet files.\n","\n","        Args:\n","        - regex_path (str): Regular expression to match Parquet file paths.\n","        - ending_with (str): Ending to filter feature names.\n","\n","        Returns:\n","        - pl.DataFrame: DataFrame containing feature definitions, data types, and file locations.\n","        \"\"\"\n","        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\").filter(\n","            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n","        )\n","        feat_defs.sort(by=[\"Variable\"])\n","\n","        feats: list[pl.String] = feat_defs[\"Variable\"].to_list()\n","        feats.sort()\n","\n","        occurrences: list[list] = [[set(), set()] for _ in range(feat_defs.height)]\n","\n","        for path in glob(str(regex_path)):\n","            df_schema: dict = pl.read_parquet_schema(path)\n","\n","            for feat, dtype in df_schema.items():\n","                index: int = Utility.find_index(feats, feat)\n","                if index != None:\n","                    occurrences[index][0].add(Utility.dtype_to_str(dtype))\n","                    occurrences[index][1].add(Path(path).stem)\n","\n","        data_types: list[str] = [None] * feat_defs.height\n","        file_locs: list[str] = [None] * feat_defs.height\n","\n","        for i, feat in enumerate(feats):\n","            data_types[i] = list(occurrences[i][0])\n","            file_locs[i] = list(occurrences[i][1])\n","\n","        feat_defs = feat_defs.with_columns(pl.Series(data_types).alias(\"Data_Type(s)\"))\n","        feat_defs = feat_defs.with_columns(pl.Series(file_locs).alias(\"File_Loc(s)\"))\n","\n","        return feat_defs\n","\n","    def reduce_memory_usage(df: pl.DataFrame, name) -> pl.DataFrame:\n","        \"\"\"\n","        Reduces memory usage of a DataFrame by converting column types.\n","\n","        Args:\n","        - df (pl.DataFrame): DataFrame to optimize.\n","        - name (str): Name of the DataFrame.\n","\n","        Returns:\n","        - pl.DataFrame: Optimized DataFrame.\n","        \"\"\"\n","        print(\n","            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n","        )\n","\n","        int_types = [\n","            pl.Int8,\n","            pl.Int16,\n","            pl.Int32,\n","            pl.Int64,\n","            pl.UInt8,\n","            pl.UInt16,\n","            pl.UInt32,\n","            pl.UInt64,\n","        ]\n","        float_types = [pl.Float32, pl.Float64]\n","\n","        for col in df.columns:\n","            col_type = df[col].dtype\n","            if col_type in int_types + float_types:\n","                c_min = df[col].min()\n","                c_max = df[col].max()\n","\n","                if c_min is not None and c_max is not None:\n","                    if col_type in int_types:\n","                        if c_min >= 0:\n","                            if (\n","                                c_min >= np.iinfo(np.uint8).min\n","                                and c_max <= np.iinfo(np.uint8).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.UInt8))\n","                            elif (\n","                                c_min >= np.iinfo(np.uint16).min\n","                                and c_max <= np.iinfo(np.uint16).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.UInt16))\n","                            elif (\n","                                c_min >= np.iinfo(np.uint32).min\n","                                and c_max <= np.iinfo(np.uint32).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.UInt32))\n","                            elif (\n","                                c_min >= np.iinfo(np.uint64).min\n","                                and c_max <= np.iinfo(np.uint64).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.UInt64))\n","                        else:\n","                            if (\n","                                c_min >= np.iinfo(np.int8).min\n","                                and c_max <= np.iinfo(np.int8).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.Int8))\n","                            elif (\n","                                c_min >= np.iinfo(np.int16).min\n","                                and c_max <= np.iinfo(np.int16).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.Int16))\n","                            elif (\n","                                c_min >= np.iinfo(np.int32).min\n","                                and c_max <= np.iinfo(np.int32).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.Int32))\n","                            elif (\n","                                c_min >= np.iinfo(np.int64).min\n","                                and c_max <= np.iinfo(np.int64).max\n","                            ):\n","                                df = df.with_columns(df[col].cast(pl.Int64))\n","                    elif col_type in float_types:\n","                        if (\n","                            c_min > np.finfo(np.float32).min\n","                            and c_max < np.finfo(np.float32).max\n","                        ):\n","                            df = df.with_columns(df[col].cast(pl.Float32))\n","\n","        print(\n","            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n","        )\n","\n","        return df\n","\n","    def to_pandas(df: pl.DataFrame, cat_cols: list[str] = None) -> (pd.DataFrame, list[str]):  # type: ignore\n","        \"\"\"\n","        Converts a Polars DataFrame to a Pandas DataFrame.\n","\n","        Args:\n","        - df (pl.DataFrame): Polars DataFrame to convert.\n","        - cat_cols (list[str]): List of categorical columns. Default is None.\n","\n","        Returns:\n","        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n","        \"\"\"\n","        df: pd.DataFrame = df.to_pandas()\n","\n","        if cat_cols is None:\n","            cat_cols = list(df.select_dtypes(\"object\").columns)\n","\n","        df[cat_cols] = df[cat_cols].astype(\"str\")\n","\n","        return df, cat_cols"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:47.910676Z","iopub.status.busy":"2024-05-15T00:26:47.910274Z","iopub.status.idle":"2024-05-15T00:26:47.918475Z","shell.execute_reply":"2024-05-15T00:26:47.917607Z","shell.execute_reply.started":"2024-05-15T00:26:47.910636Z"},"trusted":true},"outputs":[],"source":["# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"P\")\n","# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"M\")\n","# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"A\")\n","# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"D\")\n","# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"T\")\n","# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"L\")\n","# feat_defs:pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n","# with pl.Config(fmt_str_lengths=1000, tbl_rows=-1, tbl_width_chars=180):\n","#     print(feat_defs)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:47.920983Z","iopub.status.busy":"2024-05-15T00:26:47.920664Z","iopub.status.idle":"2024-05-15T00:26:47.937047Z","shell.execute_reply":"2024-05-15T00:26:47.936162Z","shell.execute_reply.started":"2024-05-15T00:26:47.920959Z"},"trusted":true},"outputs":[],"source":["class Aggregator:\n","    @staticmethod\n","    def max_expr(df: pl.LazyFrame) -> list[pl.Series]:\n","        \"\"\"\n","        Generates expressions for calculating maximum values for specific columns.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - list[pl.Series]: List of expressions for maximum values.\n","        \"\"\"\n","        cols: list[str] = [\n","            col\n","            for col in df.columns\n","            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n","        ]\n","\n","        expr_max: list[pl.Series] = [\n","            pl.col(col).max().alias(f\"max_{col}\") for col in cols\n","        ]\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def min_expr(df: pl.LazyFrame) -> list[pl.Series]:\n","        \"\"\"\n","        Generates expressions for calculating minimum values for specific columns.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - list[pl.Series]: List of expressions for minimum values.\n","        \"\"\"\n","        cols: list[str] = [\n","            col\n","            for col in df.columns\n","            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n","        ]\n","\n","        expr_min: list[pl.Series] = [\n","            pl.col(col).min().alias(f\"min_{col}\") for col in cols\n","        ]\n","\n","        return expr_min\n","\n","    @staticmethod\n","    def mean_expr(df: pl.LazyFrame) -> list[pl.Series]:\n","        \"\"\"\n","        Generates expressions for calculating mean values for specific columns.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - list[pl.Series]: List of expressions for mean values.\n","        \"\"\"\n","        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n","\n","        expr_mean: list[pl.Series] = [\n","            pl.col(col).mean().alias(f\"mean_{col}\") for col in cols\n","        ]\n","\n","        return expr_mean\n","\n","    @staticmethod\n","    def var_expr(df: pl.LazyFrame) -> list[pl.Series]:\n","        \"\"\"\n","        Generates expressions for calculating variance for specific columns.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - list[pl.Series]: List of expressions for variance.\n","        \"\"\"\n","        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n","\n","        expr_mean: list[pl.Series] = [\n","            pl.col(col).var().alias(f\"var_{col}\") for col in cols\n","        ]\n","\n","        return expr_mean\n","\n","    @staticmethod\n","    def mode_expr(df: pl.LazyFrame) -> list[pl.Series]:\n","        \"\"\"\n","        Generates expressions for calculating mode values for specific columns.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - list[pl.Series]: List of expressions for mode values.\n","        \"\"\"\n","        cols: list[str] = [col for col in df.columns if col.endswith(\"M\")]\n","\n","        expr_mode: list[pl.Series] = [\n","            pl.col(col).drop_nulls().mode().first().alias(f\"mode_{col}\") for col in cols\n","        ]\n","\n","        return expr_mode\n","\n","    @staticmethod\n","    def get_exprs(df: pl.LazyFrame) -> list[pl.Series]:\n","        \"\"\"\n","        Combines expressions for maximum, mean, and variance calculations.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - list[pl.Series]: List of combined expressions.\n","        \"\"\"\n","        exprs = (\n","            Aggregator.max_expr(df) + Aggregator.mean_expr(df) + Aggregator.var_expr(df)\n","        )\n","\n","        return exprs"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:47.939396Z","iopub.status.busy":"2024-05-15T00:26:47.938388Z","iopub.status.idle":"2024-05-15T00:26:47.952385Z","shell.execute_reply":"2024-05-15T00:26:47.951556Z","shell.execute_reply.started":"2024-05-15T00:26:47.939363Z"},"trusted":true},"outputs":[],"source":["class SchemaGen:\n","    @staticmethod\n","    def change_dtypes(df: pl.LazyFrame) -> pl.LazyFrame:\n","        \"\"\"\n","        Changes the data types of columns in the DataFrame.\n","\n","        Args:\n","        - df (pl.LazyFrame): Input LazyFrame.\n","\n","        Returns:\n","        - pl.LazyFrame: LazyFrame with modified data types.\n","        \"\"\"\n","        for col in df.columns:\n","            if col == \"case_id\":\n","                df = df.with_columns(pl.col(col).cast(pl.UInt32).alias(col))\n","            elif col in [\"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.UInt16).alias(col))\n","            elif col == \"date_decision\" or col[-1] == \"D\":\n","                df = df.with_columns(pl.col(col).cast(pl.Date).alias(col))\n","            elif col[-1] in [\"P\", \"A\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.String))\n","        return df\n","\n","    @staticmethod\n","    def scan_files(glob_path: str, depth: int = None):\n","        chunks = []\n","        for path in glob(str(glob_path)):\n","            df = pl.read_parquet(path, low_memory=True, rechunk=True)\n","            df = df.pipe(SchemaGen.change_dtypes)\n","            if depth in [1, 2]:\n","                df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","            chunks.append(df)\n","        df = pl.concat(chunks, how=\"vertical_relaxed\")\n","        del chunks\n","        gc.collect()\n","        df = df.unique(subset=[\"case_id\"])\n","        return df\n","\n","    @staticmethod\n","    def join_dataframes(df_base, depth_0, depth_1, depth_2):\n","        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n","            df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n","        return df_base\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:47.954021Z","iopub.status.busy":"2024-05-15T00:26:47.953671Z","iopub.status.idle":"2024-05-15T00:26:47.971691Z","shell.execute_reply":"2024-05-15T00:26:47.970809Z","shell.execute_reply.started":"2024-05-15T00:26:47.953992Z"},"trusted":true},"outputs":[],"source":["def filter_cols(df: pl.DataFrame) -> pl.DataFrame:\n","    \"\"\"\n","    Filters columns in the DataFrame based on null percentage and unique values for string columns.\n","\n","    Args:\n","    - df (pl.DataFrame): Input DataFrame.\n","\n","    Returns:\n","    - pl.DataFrame: DataFrame with filtered columns.\n","    \"\"\"\n","    for col in df.columns:\n","        if col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]:\n","            null_pct = df[col].is_null().mean()\n","\n","            if null_pct > 0.95:\n","                df = df.drop(col)\n","\n","    for col in df.columns:\n","        if (col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]) & (\n","            df[col].dtype == pl.String\n","        ):\n","            freq = df[col].n_unique()\n","\n","            if (freq > 200) | (freq == 1):\n","                df = df.drop(col)\n","\n","    return df\n","\n","\n","def transform_cols(df: pl.DataFrame) -> pl.DataFrame:\n","    \"\"\"\n","    Transforms columns in the DataFrame according to predefined rules.\n","\n","    Args:\n","    - df (pl.DataFrame): Input DataFrame.\n","\n","    Returns:\n","    - pl.DataFrame: DataFrame with transformed columns.\n","    \"\"\"\n","    if \"riskassesment_302T\" in df.columns:\n","        if df[\"riskassesment_302T\"].dtype == pl.Null:\n","            df = df.with_columns(\n","                [\n","                    pl.Series(\n","                        \"riskassesment_302T_rng\", df[\"riskassesment_302T\"], pl.UInt8\n","                    ),\n","                    pl.Series(\n","                        \"riskassesment_302T_mean\", df[\"riskassesment_302T\"], pl.UInt8\n","                    ),\n","                ]\n","            )\n","        else:\n","            pct_low: pl.Series = (\n","                df[\"riskassesment_302T\"]\n","                .str.split(\" - \")\n","                .apply(lambda x: x[0].replace(\"%\", \"\"))\n","                .cast(pl.UInt8)\n","            )\n","            pct_high: pl.Series = (\n","                df[\"riskassesment_302T\"]\n","                .str.split(\" - \")\n","                .apply(lambda x: x[1].replace(\"%\", \"\"))\n","                .cast(pl.UInt8)\n","            )\n","\n","            diff: pl.Series = pct_high - pct_low\n","            avg: pl.Series = ((pct_low + pct_high) / 2).cast(pl.Float32)\n","\n","            del pct_high, pct_low\n","            gc.collect()\n","\n","            df = df.with_columns(\n","                [\n","                    diff.alias(\"riskassesment_302T_rng\"),\n","                    avg.alias(\"riskassesment_302T_mean\"),\n","                ]\n","            )\n","\n","        df.drop(\"riskassesment_302T\")\n","\n","    return df\n","\n","\n","def handle_dates(df: pl.DataFrame) -> pl.DataFrame:\n","    \"\"\"\n","    Handles date columns in the DataFrame.\n","\n","    Args:\n","    - df (pl.DataFrame): Input DataFrame.\n","\n","    Returns:\n","    - pl.DataFrame: DataFrame with transformed date columns.\n","    \"\"\"\n","    for col in df.columns:\n","        if col.endswith(\"D\"):\n","            df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n","            df = df.with_columns(pl.col(col).dt.total_days().cast(pl.Int32))\n","\n","    df = df.rename(\n","        {\n","            \"MONTH\": \"month\",\n","            \"WEEK_NUM\": \"week_num\"\n","        }\n","    )\n","            \n","    df = df.with_columns(\n","        [\n","            pl.col(\"date_decision\").dt.year().alias(\"year\").cast(pl.Int16),\n","            pl.col(\"date_decision\").dt.day().alias(\"day\").cast(pl.UInt8),\n","        ]\n","    )\n","\n","    #return df.drop(\"date_decision\")\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:26:47.975509Z","iopub.status.busy":"2024-05-15T00:26:47.975244Z","iopub.status.idle":"2024-05-15T00:29:29.707398Z","shell.execute_reply":"2024-05-15T00:29:29.706503Z","shell.execute_reply.started":"2024-05-15T00:26:47.975487Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory usage of dataframe \"df_train\" is 5702.3227 MB.\n","Memory usage of dataframe \"df_train\" became 3656.7333 MB.\n","Train data shape: (1526659, 473)\n"]},{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (10, 473)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>date_decision</th><th>month</th><th>week_num</th><th>target</th><th>assignmentdate_238D</th><th>assignmentdate_4527235D</th><th>birthdate_574D</th><th>contractssum_5085716L</th><th>dateofbirth_337D</th><th>days120_123L</th><th>days180_256L</th><th>days30_165L</th><th>days360_512L</th><th>days90_310L</th><th>description_5085714M</th><th>education_1103M</th><th>education_88M</th><th>firstquarter_103L</th><th>fourthquarter_440L</th><th>maritalst_385M</th><th>maritalst_893M</th><th>numberofqueries_373L</th><th>pmtaverage_3A</th><th>pmtaverage_4527227A</th><th>pmtcount_4527229L</th><th>pmtcount_693L</th><th>pmtscount_423L</th><th>pmtssum_45A</th><th>requesttype_4525192L</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>secondquarter_766L</th><th>thirdquarter_1082L</th><th>actualdpdtolerance_344P</th><th>amtinstpaidbefduel24m_4187115A</th><th>&hellip;</th><th>mean_mainoccupationinc_384A</th><th>max_amount_416A</th><th>max_num_group1_10</th><th>max_openingdate_313D</th><th>mean_amount_416A</th><th>mean_openingdate_313D</th><th>max_num_group1_11</th><th>max_openingdate_857D</th><th>mean_openingdate_857D</th><th>max_collater_typofvalofguarant_298M</th><th>max_collater_typofvalofguarant_407M</th><th>max_collater_valueofguarantee_1124L</th><th>max_collater_valueofguarantee_876L</th><th>max_collaterals_typeofguarante_359M</th><th>max_collaterals_typeofguarante_669M</th><th>max_num_group1_12</th><th>max_num_group2</th><th>max_pmts_dpd_1073P</th><th>max_pmts_dpd_303P</th><th>max_pmts_month_158T</th><th>max_pmts_month_706T</th><th>max_pmts_overdue_1140A</th><th>max_pmts_overdue_1152A</th><th>max_pmts_year_1139T</th><th>max_pmts_year_507T</th><th>max_subjectroles_name_541M</th><th>max_subjectroles_name_838M</th><th>mean_pmts_dpd_1073P</th><th>mean_pmts_dpd_303P</th><th>mean_pmts_overdue_1140A</th><th>mean_pmts_overdue_1152A</th><th>var_pmts_dpd_1073P</th><th>var_pmts_dpd_303P</th><th>var_pmts_overdue_1140A</th><th>var_pmts_overdue_1152A</th><th>year</th><th>day</th></tr><tr><td>u32</td><td>date</td><td>u32</td><td>u8</td><td>u8</td><td>i16</td><td>u8</td><td>i16</td><td>f32</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>i8</td><td>u8</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>u8</td><td>i16</td><td>f32</td><td>i16</td><td>u8</td><td>i16</td><td>i16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>u16</td><td>u8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>u16</td><td>u8</td></tr></thead><tbody><tr><td>2629117</td><td>2019-10-07</td><td>201910</td><td>39</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-16684</td><td>2.0</td><td>3.0</td><td>1.0</td><td>8.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>7.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>8.0</td><td>null</td><td>null</td><td>null</td><td>2.0</td><td>2.0</td><td>1800.0</td><td>&quot;DEDUCTION_6&quot;</td><td>14</td><td>14</td><td>null</td><td>4.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>70000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>35</td><td>0.0</td><td>1.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.093103</td><td>0.0</td><td>0.0</td><td>2019</td><td>7</td></tr><tr><td>982186</td><td>2020-05-12</td><td>202005</td><td>71</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-8501</td><td>5.0</td><td>5.0</td><td>0.0</td><td>5.0</td><td>4.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>4.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>5.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>null</td><td>14</td><td>1.0</td><td>0.0</td><td>null</td><td>null</td><td>&hellip;</td><td>34000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>23</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2020</td><td>12</td></tr><tr><td>2667122</td><td>2020-02-14</td><td>202002</td><td>58</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-10271</td><td>2.0</td><td>4.0</td><td>0.0</td><td>7.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>7.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>7.0</td><td>6.0</td><td>0.0</td><td>101276.0</td><td>&hellip;</td><td>40000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>5</td><td>35</td><td>0.0</td><td>89.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.736</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>2.191011</td><td>0.0</td><td>0.033079</td><td>0.0</td><td>137.497192</td><td>0.0</td><td>0.023516</td><td>2020</td><td>14</td></tr><tr><td>666975</td><td>2019-04-07</td><td>201904</td><td>13</td><td>0</td><td>null</td><td>null</td><td>-13155</td><td>null</td><td>-13155</td><td>0.0</td><td>4.0</td><td>0.0</td><td>7.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>7.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>7.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>5.0</td><td>35606.605469</td><td>null</td><td>14</td><td>null</td><td>null</td><td>7.0</td><td>4.0</td><td>0.0</td><td>null</td><td>&hellip;</td><td>60000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>35</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>7</td></tr><tr><td>1802518</td><td>2020-02-29</td><td>202002</td><td>60</td><td>0</td><td>null</td><td>14</td><td>null</td><td>null</td><td>-22096</td><td>5.0</td><td>11.0</td><td>0.0</td><td>18.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>6.0</td><td>8.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>18.0</td><td>null</td><td>5723.200195</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>&quot;PENSION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>7.0</td><td>5.0</td><td>0.0</td><td>4719.600098</td><td>&hellip;</td><td>31000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>35</td><td>1272.0</td><td>189.0</td><td>12.0</td><td>12.0</td><td>97651.375</td><td>4939.600098</td><td>2021.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>983.625</td><td>42.299999</td><td>45461.105469</td><td>2039.719971</td><td>109756.9375</td><td>4278.536621</td><td>1.0461e9</td><td>5892761.5</td><td>2020</td><td>29</td></tr><tr><td>888092</td><td>2019-12-06</td><td>201912</td><td>48</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-7978</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>&hellip;</td><td>52000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>11</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>6</td></tr><tr><td>1503884</td><td>2019-08-25</td><td>201908</td><td>33</td><td>0</td><td>null</td><td>null</td><td>-24434</td><td>null</td><td>-24434</td><td>4.0</td><td>4.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>4.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>14</td><td>null</td><td>null</td><td>1.0</td><td>3.0</td><td>0.0</td><td>24100.0</td><td>&hellip;</td><td>60000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>1</td><td>23</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>25</td></tr><tr><td>1745378</td><td>2020-01-12</td><td>202001</td><td>53</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-12064</td><td>1.0</td><td>2.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>5.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>2.0</td><td>4.0</td><td>0.0</td><td>31541.138672</td><td>&hellip;</td><td>100000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>1</td><td>35</td><td>0.0</td><td>182.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>28910.146484</td><td>2020.0</td><td>2019.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>29.529411</td><td>0.0</td><td>8059.35791</td><td>0.0</td><td>2469.347656</td><td>0.0</td><td>8.448316e7</td><td>2020</td><td>12</td></tr><tr><td>963072</td><td>2020-02-24</td><td>202002</td><td>59</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-17130</td><td>2.0</td><td>3.0</td><td>1.0</td><td>7.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>3.0</td><td>&quot;a7fcb6e5&quot;</td><td>&quot;a55475b1&quot;</td><td>7.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>3.0</td><td>3.0</td><td>null</td><td>null</td><td>&hellip;</td><td>30000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>3.207e6</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>38</td><td>35</td><td>0.0</td><td>1033.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>15534.600586</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>74.717392</td><td>0.0</td><td>1736.525879</td><td>0.0</td><td>50908.300781</td><td>0.0</td><td>1.8895662e7</td><td>2020</td><td>24</td></tr><tr><td>1240022</td><td>2019-01-04</td><td>201901</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>&hellip;</td><td>50000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019</td><td>4</td></tr></tbody></table></div>"],"text/plain":["shape: (10, 473)\n","┌─────────┬───────────────┬────────┬──────────┬───┬─────────────────┬─────────────────┬──────┬─────┐\n","│ case_id ┆ date_decision ┆ month  ┆ week_num ┆ … ┆ var_pmts_overdu ┆ var_pmts_overdu ┆ year ┆ day │\n","│ ---     ┆ ---           ┆ ---    ┆ ---      ┆   ┆ e_1140A         ┆ e_1152A         ┆ ---  ┆ --- │\n","│ u32     ┆ date          ┆ u32    ┆ u8       ┆   ┆ ---             ┆ ---             ┆ u16  ┆ u8  │\n","│         ┆               ┆        ┆          ┆   ┆ f32             ┆ f32             ┆      ┆     │\n","╞═════════╪═══════════════╪════════╪══════════╪═══╪═════════════════╪═════════════════╪══════╪═════╡\n","│ 2629117 ┆ 2019-10-07    ┆ 201910 ┆ 39       ┆ … ┆ 0.0             ┆ 0.0             ┆ 2019 ┆ 7   │\n","│ 982186  ┆ 2020-05-12    ┆ 202005 ┆ 71       ┆ … ┆ 0.0             ┆ 0.0             ┆ 2020 ┆ 12  │\n","│ 2667122 ┆ 2020-02-14    ┆ 202002 ┆ 58       ┆ … ┆ 0.0             ┆ 0.023516        ┆ 2020 ┆ 14  │\n","│ 666975  ┆ 2019-04-07    ┆ 201904 ┆ 13       ┆ … ┆ 0.0             ┆ null            ┆ 2019 ┆ 7   │\n","│ 1802518 ┆ 2020-02-29    ┆ 202002 ┆ 60       ┆ … ┆ 1.0461e9        ┆ 5892761.5       ┆ 2020 ┆ 29  │\n","│ 888092  ┆ 2019-12-06    ┆ 201912 ┆ 48       ┆ … ┆ 0.0             ┆ null            ┆ 2019 ┆ 6   │\n","│ 1503884 ┆ 2019-08-25    ┆ 201908 ┆ 33       ┆ … ┆ 0.0             ┆ null            ┆ 2019 ┆ 25  │\n","│ 1745378 ┆ 2020-01-12    ┆ 202001 ┆ 53       ┆ … ┆ 0.0             ┆ 8.448316e7      ┆ 2020 ┆ 12  │\n","│ 963072  ┆ 2020-02-24    ┆ 202002 ┆ 59       ┆ … ┆ 0.0             ┆ 1.8895662e7     ┆ 2020 ┆ 24  │\n","│ 1240022 ┆ 2019-01-04    ┆ 201901 ┆ 0        ┆ … ┆ null            ┆ null            ┆ 2019 ┆ 4   │\n","└─────────┴───────────────┴────────┴──────────┴───┴─────────────────┴─────────────────┴──────┴─────┘"]},"metadata":{},"output_type":"display_data"}],"source":["data_store: dict = {\n","    \"df_base\": SchemaGen.scan_files(TRAIN_DIR / \"train_base.parquet\"),\n","    \"depth_0\": [\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_other_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_person_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n","        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n","    ],\n","}\n","\n","df_train: pl.DataFrame = (\n","    SchemaGen.join_dataframes(**data_store)\n","    .pipe(filter_cols)\n","    .pipe(transform_cols)\n","    .pipe(handle_dates)\n","    .pipe(Utility.reduce_memory_usage, \"df_train\")\n",")\n","\n","del data_store\n","gc.collect()\n","\n","print(f\"Train data shape: {df_train.shape}\")\n","display(df_train.head(10))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_train['date_decision'].is_null().sum()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_train['month'].is_null().sum()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (1_526_659, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_decision</th><th>month</th><th>week_num</th></tr><tr><td>date</td><td>u32</td><td>u8</td></tr></thead><tbody><tr><td>2019-01-01</td><td>201901</td><td>0</td></tr><tr><td>2019-01-01</td><td>201901</td><td>0</td></tr><tr><td>2019-01-01</td><td>201901</td><td>0</td></tr><tr><td>2019-01-01</td><td>201901</td><td>0</td></tr><tr><td>2019-01-01</td><td>201901</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2020-10-05</td><td>202010</td><td>91</td></tr><tr><td>2020-10-05</td><td>202010</td><td>91</td></tr><tr><td>2020-10-05</td><td>202010</td><td>91</td></tr><tr><td>2020-10-05</td><td>202010</td><td>91</td></tr><tr><td>2020-10-05</td><td>202010</td><td>91</td></tr></tbody></table></div>"],"text/plain":["shape: (1_526_659, 3)\n","┌───────────────┬────────┬──────────┐\n","│ date_decision ┆ month  ┆ week_num │\n","│ ---           ┆ ---    ┆ ---      │\n","│ date          ┆ u32    ┆ u8       │\n","╞═══════════════╪════════╪══════════╡\n","│ 2019-01-01    ┆ 201901 ┆ 0        │\n","│ 2019-01-01    ┆ 201901 ┆ 0        │\n","│ 2019-01-01    ┆ 201901 ┆ 0        │\n","│ 2019-01-01    ┆ 201901 ┆ 0        │\n","│ 2019-01-01    ┆ 201901 ┆ 0        │\n","│ …             ┆ …      ┆ …        │\n","│ 2020-10-05    ┆ 202010 ┆ 91       │\n","│ 2020-10-05    ┆ 202010 ┆ 91       │\n","│ 2020-10-05    ┆ 202010 ┆ 91       │\n","│ 2020-10-05    ┆ 202010 ┆ 91       │\n","│ 2020-10-05    ┆ 202010 ┆ 91       │\n","└───────────────┴────────┴──────────┘"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_train[['date_decision','month','week_num']].sort(['week_num','date_decision'])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["'df = df.with_columns(pl.col(\\'date_decision\\').cast(pl.Utf8))\\n\\n# \\'date_decision\\'列をdatetime型に変換\\ndf = df.with_columns(pl.col(\\'date_decision\\').str.strptime(pl.Date, \"%Y-%m-%d\"))\\n\\n# 新しい週番号を計算\\ndf = df.with_columns(\\n    (pl.col(\\'date_decision\\').dt.week() - 1).alias(\\'calculated_week_num\\')\\n)\\n\\n# 元の週番号と計算された週番号の差異を計算\\ndf = df.with_columns(\\n    (pl.col(\\'week_num\\') - pl.col(\\'calculated_week_num\\')).alias(\\'difference\\')\\n)'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"df = df.with_columns(pl.col('date_decision').cast(pl.Utf8))\n","\n","# 'date_decision'列をdatetime型に変換\n","df = df.with_columns(pl.col('date_decision').str.strptime(pl.Date, \"%Y-%m-%d\"))\n","\n","# 新しい週番号を計算\n","df = df.with_columns(\n","    (pl.col('date_decision').dt.week() - 1).alias('calculated_week_num')\n",")\n","\n","# 元の週番号と計算された週番号の差異を計算\n","df = df.with_columns(\n","    (pl.col('week_num') - pl.col('calculated_week_num')).alias('difference')\n",")\"\"\""]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (644, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_decision</th><th>week_num</th><th>cumulative_week_num</th></tr><tr><td>date</td><td>u8</td><td>i64</td></tr></thead><tbody><tr><td>2019-01-03</td><td>0</td><td>0</td></tr><tr><td>2019-01-23</td><td>3</td><td>3</td></tr><tr><td>2019-01-26</td><td>3</td><td>3</td></tr><tr><td>2019-01-29</td><td>4</td><td>4</td></tr><tr><td>2019-02-02</td><td>4</td><td>4</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2020-09-13</td><td>88</td><td>87</td></tr><tr><td>2020-09-20</td><td>89</td><td>88</td></tr><tr><td>2020-09-23</td><td>90</td><td>89</td></tr><tr><td>2020-10-03</td><td>91</td><td>90</td></tr><tr><td>2020-10-05</td><td>91</td><td>91</td></tr></tbody></table></div>"],"text/plain":["shape: (644, 3)\n","┌───────────────┬──────────┬─────────────────────┐\n","│ date_decision ┆ week_num ┆ cumulative_week_num │\n","│ ---           ┆ ---      ┆ ---                 │\n","│ date          ┆ u8       ┆ i64                 │\n","╞═══════════════╪══════════╪═════════════════════╡\n","│ 2019-01-03    ┆ 0        ┆ 0                   │\n","│ 2019-01-23    ┆ 3        ┆ 3                   │\n","│ 2019-01-26    ┆ 3        ┆ 3                   │\n","│ 2019-01-29    ┆ 4        ┆ 4                   │\n","│ 2019-02-02    ┆ 4        ┆ 4                   │\n","│ …             ┆ …        ┆ …                   │\n","│ 2020-09-13    ┆ 88       ┆ 87                  │\n","│ 2020-09-20    ┆ 89       ┆ 88                  │\n","│ 2020-09-23    ┆ 90       ┆ 89                  │\n","│ 2020-10-03    ┆ 91       ┆ 90                  │\n","│ 2020-10-05    ┆ 91       ┆ 91                  │\n","└───────────────┴──────────┴─────────────────────┘"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# 'date_decision'列を文字列型に変換し、日付型に解析\n","df_train = df_train.with_columns(pl.col('date_decision').cast(pl.Utf8).str.strptime(pl.Date, \"%Y-%m-%d\"))\n","\n","# 年と週番号を計算\n","df_train = df_train.with_columns([\n","    pl.col('date_decision').dt.year().alias('year'),\n","    (pl.col('date_decision').dt.week() - 1).alias('calculated_week_num')\n","])\n","\n","# 各年ごとに最大の週番号を取得\n","max_week_num_per_year = df_train.groupby('year').agg(\n","    pl.col('calculated_week_num').max().alias('max_week_num')\n",")\n","\n","# 前年度の最大週番号の累積を計算\n","cumulative_max_week_num = max_week_num_per_year.with_columns([\n","    pl.col('max_week_num').shift(1).fill_null(0).cumsum().alias('cumulative_max_week_num')\n","])\n","\n","# データフレームに結合\n","df_train = df_train.join(cumulative_max_week_num, on='year', how='left')\n","\n","# 前年度の累積最大週番号を次年度の週番号に加算\n","df_train = df_train.with_columns([\n","    (pl.col('calculated_week_num') + pl.col('cumulative_max_week_num')).alias('cumulative_week_num')\n","])\n","df_train[['date_decision','week_num','cumulative_week_num']].sort('date_decision').unique()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["shape: (2, 2)\n","┌───────┬────────┐\n","│ match ┆ count  │\n","│ ---   ┆ ---    │\n","│ bool  ┆ u32    │\n","╞═══════╪════════╡\n","│ false ┆ 541821 │\n","│ true  ┆ 984838 │\n","└───────┴────────┘\n"]}],"source":["# 一致するかどうかを確認する列を追加\n","df_train = df_train.with_columns([\n","    (pl.col('week_num') == pl.col('cumulative_week_num')).alias('match')\n","])\n","\n","# 一致する列の値を集計\n","match_counts = df_train['match'].value_counts()\n","\n","print(match_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:29:29.709140Z","iopub.status.busy":"2024-05-15T00:29:29.708842Z","iopub.status.idle":"2024-05-15T00:29:31.789671Z","shell.execute_reply":"2024-05-15T00:29:31.788744Z","shell.execute_reply.started":"2024-05-15T00:29:29.709116Z"},"trusted":true},"outputs":[],"source":["data_store: dict = {\n","    \"df_base\": SchemaGen.scan_files(TEST_DIR / \"test_base.parquet\"),\n","    \"depth_0\": [\n","        SchemaGen.scan_files(TEST_DIR / \"test_static_cb_0.parquet\"),\n","        SchemaGen.scan_files(TEST_DIR / \"test_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        SchemaGen.scan_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_other_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_person_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_deposit_1.parquet\", 1),\n","        SchemaGen.scan_files(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n","        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n","    ],\n","}\n","\n","df_test: pl.DataFrame = (\n","    SchemaGen.join_dataframes(**data_store)\n","    .pipe(transform_cols)\n","    .pipe(handle_dates)\n","    .select([col for col in df_train.columns if col != \"target\"])\n","    .pipe(Utility.reduce_memory_usage, \"df_test\")\n",")\n","\n","del data_store\n","gc.collect()\n","\n","print(f\"Test data shape: {df_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:29:31.791148Z","iopub.status.busy":"2024-05-15T00:29:31.790868Z","iopub.status.idle":"2024-05-15T00:29:53.959324Z","shell.execute_reply":"2024-05-15T00:29:53.958327Z","shell.execute_reply.started":"2024-05-15T00:29:31.791109Z"},"trusted":true},"outputs":[],"source":["df_train, cat_cols = Utility.to_pandas(df_train)\n","df_test, cat_cols = Utility.to_pandas(df_test, cat_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:29:53.962394Z","iopub.status.busy":"2024-05-15T00:29:53.962109Z","iopub.status.idle":"2024-05-15T00:29:53.971446Z","shell.execute_reply":"2024-05-15T00:29:53.970438Z","shell.execute_reply.started":"2024-05-15T00:29:53.962370Z"},"trusted":true},"outputs":[],"source":["class VotingModel(BaseEstimator, ClassifierMixin):\n","    \"\"\"\n","    A voting ensemble model that combines predictions from multiple estimators.\n","\n","    Parameters:\n","    - estimators (list): List of base estimators.\n","\n","    Attributes:\n","    - estimators (list): List of base estimators.\n","\n","    Methods:\n","    - fit(X, y=None): Fit the model to the training data.\n","    - predict(X): Predict class labels for samples.\n","    - predict_proba(X): Predict class probabilities for samples.\n","    \"\"\"\n","\n","    def __init__(self, estimators: list[BaseEstimator]):\n","        \"\"\"\n","        Initialize the VotingModel with a list of base estimators.\n","\n","        Args:\n","        - estimators (list): List of base estimators.\n","        \"\"\"\n","        super().__init__()\n","        self.estimators = estimators\n","\n","    def fit(self, X, y=None):\n","        \"\"\"\n","        Fit the model to the training data.\n","\n","        Args:\n","        - X: Input features.\n","        - y: Target labels (ignored).\n","\n","        Returns:\n","        - self: Returns the instance itself.\n","        \"\"\"\n","        return self\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predict class labels for samples.\n","\n","        Args:\n","        - X: Input features.\n","\n","        Returns:\n","        - numpy.ndarray: Predicted class labels.\n","        \"\"\"\n","        y_preds = [estimator.predict(X) for estimator in self.estimators]\n","        return np.mean(y_preds, axis=0)\n","\n","    def predict_proba(self, X):\n","        \"\"\"\n","        Predict class probabilities for samples.\n","\n","        Args:\n","        - X: Input features.\n","\n","        Returns:\n","        - numpy.ndarray: Predicted class probabilities.\n","        \"\"\"\n","        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n","        return np.mean(y_preds, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:29:53.973697Z","iopub.status.busy":"2024-05-15T00:29:53.972916Z","iopub.status.idle":"2024-05-15T00:29:53.994382Z","shell.execute_reply":"2024-05-15T00:29:53.993352Z","shell.execute_reply.started":"2024-05-15T00:29:53.973670Z"},"trusted":true},"outputs":[],"source":["df_subm: pd.DataFrame = pd.read_csv(ROOT / \"sample_submission.csv\")\n","df_subm = df_subm.set_index(\"case_id\")\n","\n","device: str = \"gpu\"\n","est_cnt: int = 6000\n","\n","DRY_RUN = True if df_subm.shape[0] == 10 else False\n","if DRY_RUN:\n","    device = \"cpu\"\n","    df_train = df_train.iloc[:50000]\n","    est_cnt: int = 600\n","\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:29:53.995934Z","iopub.status.busy":"2024-05-15T00:29:53.995650Z","iopub.status.idle":"2024-05-15T00:37:25.759807Z","shell.execute_reply":"2024-05-15T00:37:25.758872Z","shell.execute_reply.started":"2024-05-15T00:29:53.995910Z"},"trusted":true},"outputs":[],"source":["X = df_train.drop(columns=[\"target\", \"case_id\", \"week_num\"])\n","y = df_train[\"target\"]\n","\n","weeks = df_train[\"week_num\"]\n","\n","#del df_train\n","gc.collect()\n","\n","cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n","\n","params1 = {\n","    \"boosting_type\": \"gbdt\",\n","    \"colsample_bynode\": 0.8,\n","    \"colsample_bytree\": 0.8,\n","    \"device\": device,\n","    \"extra_trees\": True,\n","    \"learning_rate\": 0.05,\n","    \"l1_regularization\": 0.1,\n","    \"l2_regularization\": 10,\n","    \"max_depth\": 20,\n","    \"metric\": \"auc\",\n","    \"n_estimators\": 2000,\n","    \"num_leaves\": 64,\n","    \"objective\": \"binary\",\n","    \"random_state\": 42,\n","    \"verbose\": -1,\n","}\n","\n","params2 = {\n","    \"boosting_type\": \"gbdt\",\n","    \"colsample_bynode\": 0.8,\n","    \"colsample_bytree\": 0.8,\n","    \"device\": device,\n","    \"extra_trees\": True,\n","    \"learning_rate\": 0.03,\n","    \"l1_regularization\": 0.1,\n","    \"l2_regularization\": 10,\n","    \"max_depth\": 16,\n","    \"metric\": \"auc\",\n","    \"n_estimators\": 2000,\n","    \"num_leaves\": 54,\n","    \"objective\": \"binary\",\n","    \"random_state\": 42,\n","    \"verbose\": -1,\n","}\n","\n","fitted_models_cat = []\n","fitted_models_lgb = []\n","\n","cv_scores_cat = []\n","cv_scores_lgb = []\n","\n","iter_cnt = 0\n","for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n","    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n","    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n","    '''\n","    train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n","    val_pool = Pool(X_valid, y_valid, cat_features=cat_cols)\n","\n","    clf = CatBoostClassifier(\n","        best_model_min_trees = 1000,\n","        boosting_type = \"Plain\",\n","        eval_metric = \"AUC\",\n","        iterations = est_cnt,\n","        learning_rate = 0.05,\n","        l2_leaf_reg = 10,\n","        max_leaves = 64,\n","        random_seed = 42,\n","        task_type = \"GPU\",\n","        use_best_model = True\n","    )\n","\n","    clf.fit(train_pool, eval_set=val_pool, verbose=False)\n","    fitted_models_cat.append(clf)\n","\n","    y_pred_valid = clf.predict_proba(X_valid)[:, 1]\n","    auc_score = roc_auc_score(y_valid, y_pred_valid)\n","    cv_scores_cat.append(auc_score)\n","    '''\n","    X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n","    X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n","\n","    if iter_cnt % 2 == 0:\n","        model = lgb.LGBMClassifier(**params1)\n","    else:\n","        model = lgb.LGBMClassifier(**params2)\n","\n","    model.fit(\n","        X_train,\n","        y_train,\n","        eval_set=[(X_valid, y_valid)],\n","        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)],\n","    )\n","    fitted_models_lgb.append(model)\n","\n","    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n","    auc_score = roc_auc_score(y_valid, y_pred_valid)\n","    cv_scores_lgb.append(auc_score)\n","\n","    iter_cnt += 1\n","\n","model = VotingModel(fitted_models_cat + fitted_models_lgb)\n","\n","#print(f\"\\nCV AUC scores for CatBoost: {cv_scores_cat}\")\n","#print(f\"Maximum CV AUC score for Catboost: {max(cv_scores_cat)}\", end=\"\\n\\n\")\n","\n","\n","print(f\"CV AUC scores for LGBM: {cv_scores_lgb}\")\n","print(f\"Maximum CV AUC score for LGBM: {max(cv_scores_lgb)}\", end=\"\\n\\n\")\n","\n","del X, y\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["Training until validation scores don't improve for 100 rounds\n","[100]\tvalid_0's auc: 0.829186\n","[200]\tvalid_0's auc: 0.830062\n","Early stopping, best iteration is:\n","[143]\tvalid_0's auc: 0.832625\n","Training until validation scores don't improve for 100 rounds\n","[100]\tvalid_0's auc: 0.817886\n","[200]\tvalid_0's auc: 0.824315\n","[300]\tvalid_0's auc: 0.825302\n","Early stopping, best iteration is:\n","[277]\tvalid_0's auc: 0.82588\n","Training until validation scores don't improve for 100 rounds\n","[100]\tvalid_0's auc: 0.832977\n","[200]\tvalid_0's auc: 0.836605\n","[300]\tvalid_0's auc: 0.838039\n","Early stopping, best iteration is:\n","[288]\tvalid_0's auc: 0.838424\n","Training until validation scores don't improve for 100 rounds\n","[100]\tvalid_0's auc: 0.798351\n","[200]\tvalid_0's auc: 0.812143\n","[300]\tvalid_0's auc: 0.812793\n","Early stopping, best iteration is:\n","[251]\tvalid_0's auc: 0.81398\n","Training until validation scores don't improve for 100 rounds\n","[100]\tvalid_0's auc: 0.806045\n","...\n","[152]\tvalid_0's auc: 0.808167\n","CV AUC scores for LGBM: [0.832625157557228, 0.8258797409515442, 0.8384238678191509, 0.8139802713768391, 0.8081673991999244]\n","Maximum CV AUC score for LGBM: 0.8384238678191509"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T00:37:25.761217Z","iopub.status.busy":"2024-05-15T00:37:25.760942Z","iopub.status.idle":"2024-05-15T00:37:26.293500Z","shell.execute_reply":"2024-05-15T00:37:26.292579Z","shell.execute_reply.started":"2024-05-15T00:37:25.761195Z"},"trusted":true},"outputs":[],"source":["X_test: pd.DataFrame = df_test.drop(columns=[\"week_num\"]).set_index(\"case_id\")\n","\n","X_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n","\n","y_pred: pd.Series = pd.Series(model.predict_proba(X_test)[:, 1], index=X_test.index)\n","\n","df_subm[\"score\"] = y_pred\n","\n","display(df_subm)\n","\n","df_subm.to_csv(\"submission.csv\")\n","\n","del X_test, y_pred, df_subm\n","gc.collect()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7921029,"sourceId":50160,"sourceType":"competition"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
