{"cells":[{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:23.633949Z","iopub.status.busy":"2024-04-03T14:15:23.633619Z","iopub.status.idle":"2024-04-03T14:15:29.281138Z","shell.execute_reply":"2024-04-03T14:15:29.279638Z","shell.execute_reply.started":"2024-04-03T14:15:23.633923Z"},"trusted":true},"outputs":[],"source":["# 標準ライブラリ\n","import gc\n","import os\n","import pickle\n","import random\n","import sys\n","import warnings\n","from itertools import combinations, permutations\n","from pathlib import Path\n","\n","# サードパーティのライブラリ\n","import category_encoders as ce\n","import joblib\n","import lightgbm as lgb\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","import scipy as sp\n","import seaborn as sns\n","import torch\n","import xgboost as xgb\n","from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n","from dateutil.relativedelta import relativedelta\n","from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\n","from sklearn.model_selection import (GroupKFold, KFold, StratifiedKFold,\n","                                     StratifiedGroupKFold, TimeSeriesSplit,\n","                                     train_test_split)\n","from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n","from tqdm.auto import tqdm\n","\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings('ignore')\n","\n","import glob"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.443340Z","iopub.status.busy":"2024-04-03T14:15:29.442853Z","iopub.status.idle":"2024-04-03T14:15:29.454020Z","shell.execute_reply":"2024-04-03T14:15:29.453060Z","shell.execute_reply.started":"2024-04-03T14:15:29.443305Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    home_directory = os.path.expanduser('~/kaggle_HomeCredit/')\n","    kaggle_directory = os.path.expanduser('/kaggle/input/home-credit-credit-risk-model-stability/')\n","    \n","    train_data_path = os.path.join(home_directory, 'train/')\n","    test_data_path = os.path.join(home_directory, 'test/')\n","    \n","    OOF_DATA_PATH = os.path.join(home_directory, 'oof')\n","    MODEL_DATA_PATH = os.path.join(home_directory, 'models')\n","    SUB_DATA_PATH = os.path.join(home_directory, 'submission')\n","    \n","    VER = 28\n","    AUTHOR = 'Mira'\n","    COMPETITION = 'HomeCredit'\n","\n","    METHOD_LIST = ['lightgbm', 'xgboost', 'catboost']\n","    seed = 28\n","    n_folds = 5\n","    target_col = 'target'\n","    metric = 'auc'\n","    \n","    metric_maximize_flag = True\n","    num_boost_round = 500\n","    early_stopping_round = 200\n","    verbose = 25\n","    classification_lgb_params = {\n","        'objective': 'binary',\n","        'metric': 'auc',\n","        'learning_rate': 0.05,\n","        'seed': seed,\n","    }\n","    classification_xgb_params = {\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'logloss',\n","        'learning_rate': 0.05,\n","        'random_state': seed,\n","    }\n","\n","    classification_cat_params = {\n","        'learning_rate': 0.05,\n","        'iterations': num_boost_round,\n","        'random_seed': seed,\n","    }\n","    model_weight_dict = {'lightgbm': 0.50, 'xgboost': 0.2, 'catboost': 0.3}\n","    \n","\n","class is_kaggle:\n","    def __init__(self, Kaggle):\n","        if Kaggle == \"Yes\":\n","            self.path = Path(CFG.kaggle_directory)\n","        else:\n","            self.path = Path(CFG.home_directory)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.457169Z","iopub.status.busy":"2024-04-03T14:15:29.456719Z","iopub.status.idle":"2024-04-03T14:15:29.462321Z","shell.execute_reply":"2024-04-03T14:15:29.461464Z","shell.execute_reply.started":"2024-04-03T14:15:29.457137Z"},"trusted":true},"outputs":[],"source":["selector = is_kaggle(\"no\")"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.463975Z","iopub.status.busy":"2024-04-03T14:15:29.463423Z","iopub.status.idle":"2024-04-03T14:15:29.478538Z","shell.execute_reply":"2024-04-03T14:15:29.477337Z","shell.execute_reply.started":"2024-04-03T14:15:29.463945Z"},"trusted":true},"outputs":[],"source":["class Pipeline:\n","    @staticmethod\n","    def set_table_dtypes(df):\n","        for col in df.columns:\n","            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Int32))\n","            elif col in [\"date_decision\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","            elif col[-1] in (\"P\", \"A\"):\n","                df = df.with_columns(pl.col(col).cast(pl.Float64))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.String))\n","            elif col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Date))            \n","\n","        return df\n","    \n","    @staticmethod\n","    def handle_dates(df):\n","        for col in df.columns:\n","            if col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n","                df = df.with_columns(pl.col(col).dt.total_days())\n","                df = df.with_columns(pl.col(col).cast(pl.Float32))\n","                \n","        df = df.drop(\"date_decision\", \"MONTH\")\n","\n","        return df\n","    \n","    @staticmethod\n","    def filter_cols(df):\n","        for col in df.columns:\n","            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n","                isnull = df[col].is_null().mean()\n","\n","                if isnull > 0.95:\n","                    df = df.drop(col)\n","\n","        for col in df.columns:\n","            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n","                freq = df[col].n_unique()\n","\n","                if (freq == 1) | (freq > 200):\n","                    df = df.drop(col)\n","\n","        return df"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.482964Z","iopub.status.busy":"2024-04-03T14:15:29.482199Z","iopub.status.idle":"2024-04-03T14:15:29.496015Z","shell.execute_reply":"2024-04-03T14:15:29.495267Z","shell.execute_reply.started":"2024-04-03T14:15:29.482931Z"},"trusted":true},"outputs":[],"source":["class Aggregator:\n","    @staticmethod\n","    def num_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def date_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def str_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n","        \n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def other_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n","        \n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","\n","        return expr_max\n","    \n","    @staticmethod\n","    def count_expr(df):\n","        cols = [col for col in df.columns if \"num_group\" in col]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def get_exprs(df):\n","        exprs = Aggregator.num_expr(df) + \\\n","                Aggregator.date_expr(df) + \\\n","                Aggregator.str_expr(df) + \\\n","                Aggregator.other_expr(df) + \\\n","                Aggregator.count_expr(df)\n","\n","        return exprs"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.497430Z","iopub.status.busy":"2024-04-03T14:15:29.497174Z","iopub.status.idle":"2024-04-03T14:15:29.512214Z","shell.execute_reply":"2024-04-03T14:15:29.511360Z","shell.execute_reply.started":"2024-04-03T14:15:29.497407Z"},"trusted":true},"outputs":[],"source":["def read_file(path, depth=None):\n","    df = pl.read_parquet(path)\n","    df = df.pipe(Pipeline.set_table_dtypes)\n","    \n","    if depth in [1, 2]:\n","        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    \n","    return df\n","\n","def read_files(regex_path, depth=None):\n","    chunks = []\n","    for path in glob.glob(str(regex_path)):\n","        df = pl.read_parquet(path)\n","        df = df.pipe(Pipeline.set_table_dtypes)\n","        \n","        if depth in [1, 2]:\n","            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","        \n","        chunks.append(df)\n","        \n","    df = pl.concat(chunks, how=\"vertical_relaxed\")\n","    df = df.unique(subset=[\"case_id\"])\n","    \n","    return df"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.514033Z","iopub.status.busy":"2024-04-03T14:15:29.513575Z","iopub.status.idle":"2024-04-03T14:15:29.522227Z","shell.execute_reply":"2024-04-03T14:15:29.521353Z","shell.execute_reply.started":"2024-04-03T14:15:29.514002Z"},"trusted":true},"outputs":[],"source":["def feature_eng(df_base, depth_0, depth_1, depth_2):\n","    df_base = (\n","        df_base\n","        .with_columns(\n","            month_decision = pl.col(\"date_decision\").dt.month(),\n","            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n","        )\n","    )\n","        \n","    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n","        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n","        \n","    df_base = df_base.pipe(Pipeline.handle_dates)\n","    \n","    return df_base"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.523721Z","iopub.status.busy":"2024-04-03T14:15:29.523398Z","iopub.status.idle":"2024-04-03T14:15:29.534678Z","shell.execute_reply":"2024-04-03T14:15:29.533863Z","shell.execute_reply.started":"2024-04-03T14:15:29.523691Z"},"trusted":true},"outputs":[],"source":["def to_pandas(df_data, cat_cols=None):\n","    df_data = df_data.to_pandas()\n","    \n","    if cat_cols is None:\n","        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n","    \n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","    \n","    return df_data, cat_cols"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.537988Z","iopub.status.busy":"2024-04-03T14:15:29.537725Z","iopub.status.idle":"2024-04-03T14:15:29.550790Z","shell.execute_reply":"2024-04-03T14:15:29.549950Z","shell.execute_reply.started":"2024-04-03T14:15:29.537956Z"},"trusted":true},"outputs":[],"source":["def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.        \n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","    \n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if str(col_type)==\"category\":\n","            continue\n","        \n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            continue\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","    \n","    return df"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.552005Z","iopub.status.busy":"2024-04-03T14:15:29.551739Z","iopub.status.idle":"2024-04-03T14:15:29.563877Z","shell.execute_reply":"2024-04-03T14:15:29.563013Z","shell.execute_reply.started":"2024-04-03T14:15:29.551983Z"},"trusted":true},"outputs":[],"source":["ROOT = selector.path\n","TRAIN_DIR       = ROOT / \"parquet_files/train\"\n","TEST_DIR        = ROOT / \"parquet_files/test\"\n","SUB_DIR = ROOT / \"sample_submission.csv\""]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:15:29.565115Z","iopub.status.busy":"2024-04-03T14:15:29.564844Z","iopub.status.idle":"2024-04-03T14:17:37.198466Z","shell.execute_reply":"2024-04-03T14:17:37.197589Z","shell.execute_reply.started":"2024-04-03T14:15:29.565093Z"},"trusted":true},"outputs":[],"source":["train_data_store = {\n","    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n","    \"depth_0\": [\n","        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n","        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n","        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n","        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n","    ]\n","}"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:17:37.200414Z","iopub.status.busy":"2024-04-03T14:17:37.200059Z","iopub.status.idle":"2024-04-03T14:17:37.471238Z","shell.execute_reply":"2024-04-03T14:17:37.470318Z","shell.execute_reply.started":"2024-04-03T14:17:37.200380Z"},"trusted":true},"outputs":[],"source":["test_data_store = {\n","    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n","    \"depth_0\": [\n","        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n","        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n","        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n","        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n","        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n","    ]\n","}"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:17:37.472852Z","iopub.status.busy":"2024-04-03T14:17:37.472462Z","iopub.status.idle":"2024-04-03T14:18:18.246212Z","shell.execute_reply":"2024-04-03T14:18:18.245312Z","shell.execute_reply.started":"2024-04-03T14:17:37.472818Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train data shape:\t (1526659, 472)\n","train data shape:\t (10, 471)\n"]}],"source":["df_train = feature_eng(**train_data_store)\n","print(\"train data shape:\\t\", df_train.shape)\n","df_test = feature_eng(**test_data_store)\n","print(\"train data shape:\\t\", df_test.shape)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train data shape:\t (1526659, 361)\n","test data shape:\t (10, 360)\n"]}],"source":["df_train = df_train.pipe(Pipeline.filter_cols)\n","df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n","\n","print(\"train data shape:\\t\", df_train.shape)\n","print(\"test data shape:\\t\", df_test.shape)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["df_train, cat_cols = to_pandas(df_train)\n","df_test, cat_cols = to_pandas(df_test, cat_cols)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list):\n","    lgb_train = lgb.Dataset(x_train, y_train)\n","    lgb_valid = lgb.Dataset(x_valid, y_valid)\n","    model = lgb.train(\n","                params = CFG.classification_lgb_params,\n","                train_set = lgb_train,\n","                num_boost_round = CFG.num_boost_round,\n","                valid_sets = [lgb_train, lgb_valid],\n","                feval = CFG.metric,\n","                callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n","                                              verbose=CFG.verbose)]\n","            )\n","    valid_pred = model.predict(x_valid)\n","    \n","    importance_df = pd.DataFrame({\n","        'feature': features,\n","        'importance': model.feature_importance(importance_type='gain')\n","    })\n","    importance_df['importance'] = importance_df['importance'] / np.sum(importance_df['importance'])\n","    importance_df = importance_df.sort_values(by='importance', ascending=False)\n","    print(importance_df)\n","    return model, valid_pred\n","def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list):\n","    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n","    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n","    model = xgb.train(\n","                CFG.classification_xgb_params,\n","                dtrain = xgb_train,\n","                num_boost_round = CFG.num_boost_round,\n","                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n","                early_stopping_rounds = CFG.early_stopping_round,\n","                verbose_eval = CFG.verbose,\n","                feval = CFG.metric,\n","                maximize = CFG.metric_maximize_flag,\n","        )\n","    valid_pred = model.predict(xgb.DMatrix(x_valid))\n","    return model, valid_pred\n","def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list):\n","    cat_train = Pool(data=x_train, label=y_train)\n","    cat_valid = Pool(data=x_valid, label=y_valid)\n","    model = CatBoostClassifier(**CFG.classification_cat_params)\n","    model.fit(cat_train,\n","              eval_set = [cat_valid],\n","              early_stopping_rounds = CFG.early_stopping_round,\n","              verbose = CFG.verbose,\n","              use_best_model = True)\n","    valid_pred = model.predict_proba(x_valid)[:, 1]\n","    return model, valid_pred"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list):\n","    weeks = df_train[\"WEEK_NUM\"]\n","    X = df_train.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n","    y = df_train[\"target\"]\n","    \n","    oof_predictions = np.zeros(len(train_df))\n","    oof_fold = np.zeros(len(train_df))\n","    cv = StratifiedGroupKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n","    for fold, (train_index, valid_index) in enumerate(cv.split(X, y, groups=weeks)):\n","        print('-'*50)\n","        print(f'{method} training fold {fold+1}')\n","\n","        x_train = train_df[features].iloc[train_index]\n","        y_train = train_df[CFG.target_col].iloc[train_index]\n","        x_valid = train_df[features].iloc[valid_index]\n","        y_valid = train_df[CFG.target_col].iloc[valid_index]\n","        if method == 'lightgbm':\n","            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features)\n","        if method == 'xgboost':\n","            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features)\n","        if method == 'catboost':\n","            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features)\n","\n","        pickle.dump(model, open(CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n","\n","        oof_predictions[valid_index] = valid_pred\n","        oof_fold[valid_index] = fold + 1\n","        del x_train, x_valid, y_train, y_valid, model, valid_pred\n","        gc.collect()\n","\n","    score = roc_auc_score(train_df[CFG.target_col], oof_predictions)\n","    print(f'{method} our out of folds CV f1score is {score}')\n","\n","    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n","    oof_df.to_csv(CFG.OOF_DATA_PATH / f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n","\n","def Learning(input_df: pd.DataFrame, features: list):\n","    for method in CFG.METHOD_LIST:\n","        gradient_boosting_model_cv_training(method, input_df, features)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["def unified_inference(method: str, x_test: pd.DataFrame):\n","    test_pred = np.zeros(len(x_test))\n","    for fold in range(CFG.n_folds):\n","        model_path = CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl'\n","        model = pickle.load(open(model_path, 'rb'))\n","\n","        if method == 'lightgbm':\n","            pred = model.predict(x_test)\n","        elif method == 'xgboost':\n","            pred = model.predict(xgb.DMatrix(x_test))\n","        elif method == 'catboost':\n","            pred = model.predict_proba(x_test)[:, 1]\n","        else:\n","            raise ValueError(f\"Unsupported method: {method}\")\n","\n","        test_pred += pred\n","    \n","    return test_pred / CFG.n_folds\n","\n","def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list):\n","    x_test = test_df[features]\n","    test_pred = unified_inference(method, x_test)\n","    return test_pred\n","\n","def Predicting(input_df: pd.DataFrame, features: list):\n","    output_df = input_df.copy()\n","    output_df['pred_prob'] = 0\n","    for method in CFG.METHOD_LIST:\n","        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, input_df, features)\n","        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n","        output_df['target'] = np.where(output_df['pred_prob'] >= 0.5, 1, 0)\n","    return output_df"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["def target_enc(df,test,col):\n","    features = [col for col in df.columns if col != CFG.target_col]\n","    kf = KFold(n_splits=CFG.n_folds,shuffle=True,random_state = CFG.seed)\n","    encoded_features = []\n","\n","    for train_idx, val_idx in kf.split(df):\n","        X_train, X_valid = df[features].iloc[train_idx], df[features].iloc[val_idx]\n","        y_train = df[CFG.target_col].iloc[train_idx]\n","\n","        target_encoder = ce.TargetEncoder()\n","        target_encoder.fit(X_train[col], y_train)\n","\n","        X_valid[f'{col}_target_Encoded'] = target_encoder.transform(X_valid[col])\n","        encoded_features.append(X_valid)\n","\n","\n","    encoded_df = pd.concat(encoded_features).sort_index()\n","    df[f'{col}_target_Encoded'] = encoded_df[f'{col}_target_Encoded']\n","    \n","    target_encoder = ce.TargetEncoder()\n","    target_encoder.fit(df[[col]], df[CFG.target_col])\n","\n","    test[f'{col}_target_Encoded'] = target_encoder.transform(test[[col]])\n","    \n","    return df, test\n","\n","def encoder(df,test):\n","    object_columns = [col for col in df.columns if df[col].dtype == 'object']\n","    \n","    for col in object_columns:\n","        df,test = target_enc(df,test,col)\n","    \n","    df.drop(object_columns,axis=1,inplace=True)\n","    test.drop(object_columns,axis=1,inplace=True)\n","        \n","    return df,test\n","\n","def preprocess(df,test):\n","    df,test = encoder(df,test)\n","    features = [col for col in df_train.columns if col != CFG.target_col and col not in [\"case_id\", \"WEEK_NUM\"]]\n","    \n","    return df,test,features"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","lightgbm training fold 1\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n","\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n","\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n","\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"]}],"source":["weeks = df_train[\"WEEK_NUM\"]\n","features = [col for col in df_train.columns if col != CFG.target_col and col not in [\"case_id\", \"WEEK_NUM\"]]\n","df_train,df_test,features = preprocess(df_train,df_test)\n","\n","Learning(df_train, features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del train_data_store,test_data_store\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:18:45.266843Z","iopub.status.busy":"2024-04-03T14:18:45.266520Z","iopub.status.idle":"2024-04-03T14:37:25.409177Z","shell.execute_reply":"2024-04-03T14:37:25.407982Z","shell.execute_reply.started":"2024-04-03T14:18:45.266817Z"},"trusted":true},"outputs":[],"source":["cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n","\n","params = {\n","    \"boosting_type\": \"gbdt\",\n","    \"objective\": \"binary\",\n","    \"metric\": \"auc\",\n","    \"max_depth\": 8,\n","    \"learning_rate\": 0.05,\n","    \"n_estimators\": 1000,\n","    \"colsample_bytree\": 0.8, \n","    \"colsample_bynode\": 0.8,\n","    \"verbose\": -1,\n","    \"random_state\": CFG.seed,\n","    #\"device\": \"gpu\",\n","}\n","\n","fitted_models = []\n","\n","for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n","    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n","    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(\n","        X_train, y_train,\n","        eval_set=[(X_valid, y_valid)],\n","        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)]\n","    )\n","\n","    fitted_models.append(model)\n","\n","model = VotingModel(fitted_models)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:37:25.410851Z","iopub.status.busy":"2024-04-03T14:37:25.410467Z","iopub.status.idle":"2024-04-03T14:37:26.256453Z","shell.execute_reply":"2024-04-03T14:37:26.254927Z","shell.execute_reply.started":"2024-04-03T14:37:25.410816Z"},"trusted":true},"outputs":[],"source":["X_test = df_test.drop(columns=[\"WEEK_NUM\"])\n","X_test = X_test.set_index(\"case_id\")\n","\n","y_pred = pd.Series(model.predict_proba(X_test)[:, 1], index=X_test.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-03T14:37:26.257276Z","iopub.status.idle":"2024-04-03T14:37:26.257648Z","shell.execute_reply":"2024-04-03T14:37:26.257468Z","shell.execute_reply.started":"2024-04-03T14:37:26.257454Z"},"trusted":true},"outputs":[],"source":["df_subm = pd.read_csv(SUB_DIR)\n","df_subm = df_subm.set_index(\"case_id\")\n","\n","df_subm[\"score\"] = y_pred\n","df_subm.to_csv(\"submission.csv\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7921029,"sourceId":50160,"sourceType":"competition"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
